{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80cd81b1",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79f916d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4314]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "import subprocess as sp\n",
    "import os\n",
    "def get_gpu_memory():\n",
    "    command = \"nvidia-smi --query-gpu=memory.free --format=csv\"\n",
    "    memory_free_info = sp.check_output(command.split()).decode('ascii').split('\\n')[:-1][1:]\n",
    "    memory_free_values = [int(x.split()[0]) for i, x in enumerate(memory_free_info)]\n",
    "    return memory_free_values\n",
    "\n",
    "get_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c20c53b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import json\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "with open('test_dataset.json', 'r') as fp:\n",
    "    test_dataset = json.load(fp)\n",
    "with open('train_dataset.json', 'r') as fp:\n",
    "    train_dataset = json.load(fp)\n",
    "f = open('/data/data_codebook.json')\n",
    "data_codebook = json.load(f)\n",
    "super_set={}\n",
    "for s in data_codebook:\n",
    "    if s[2]!=\"domain_name\":\n",
    "        if s[2] not in super_set:\n",
    "            super_set[s[2]]=[]\n",
    "        if s[5] not in super_set[s[2]]:\n",
    "            super_set[s[2]].append(s[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1536de84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
    "sw = stopwords.words('english')\n",
    "\n",
    "def clean_text(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub(r\"[^a-zA-Z?.!,Â¿]+\", \" \", text) # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "\n",
    "    text = re.sub(r\"http\\S+\", \"\",text) #Removing URLs \n",
    "    #text = re.sub(r\"http\", \"\",text)\n",
    "    \n",
    "    html=re.compile(r'<.*?>') \n",
    "    \n",
    "    text = html.sub(r'',text) #Removing html tags\n",
    "    \n",
    "    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\" + '_'\n",
    "    for p in punctuations:\n",
    "        text = text.replace(p,'') #Removing punctuations\n",
    "        \n",
    "    text = [word.lower() for word in text.split() if word.lower() not in sw]\n",
    "    \n",
    "    text = \" \".join(text) #removing stopwords\n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text) #Removing emojis\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac8ed99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dataset_counts(dataset):\n",
    "    count_dataset = {\n",
    "        \"general\": {},\n",
    "        \"detailed\": {}\n",
    "    }\n",
    "    \n",
    "    for s in dataset:\n",
    "        detailed_label = s['detailed_label']\n",
    "        general_label = s[\"general_label\"]\n",
    "        \n",
    "        if detailed_label not in count_dataset[\"detailed\"]:\n",
    "            count_dataset[\"detailed\"][detailed_label] = 0\n",
    "        count_dataset[\"detailed\"][detailed_label] += 1\n",
    "\n",
    "        if general_label not in count_dataset[\"general\"]:\n",
    "            count_dataset[\"general\"][general_label] = 0\n",
    "        count_dataset[\"general\"][general_label] += 1\n",
    "    \n",
    "    return count_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8332aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_custom_dataset(balanced_dataset, total_limit, desired_percentage):\n",
    "    used_sentences = set()\n",
    "    dataset = []\n",
    "    welfare_count = 0\n",
    "    welfare_limit = int(total_limit * desired_percentage)\n",
    "    category_limits = {category: 100 for category in balanced_dataset.keys()}\n",
    "\n",
    "    # Calculate the total number of sentences in the dataset\n",
    "    total_sentences = sum(len(v) for v in balanced_dataset.values())\n",
    "\n",
    "    # First, add sentences from 'Environmental Protection'\n",
    "    for sentence in balanced_dataset['Environmental Protection']:\n",
    "        if len(dataset) >= welfare_limit:\n",
    "            break\n",
    "\n",
    "        if sentence not in used_sentences:\n",
    "            per_line_dict = {\n",
    "                \"sentence\": sentence,\n",
    "                \"detailed_label\": 'Environmental Protection',\n",
    "                \"general_label\": 'Welfare and Quality of Life'\n",
    "            }\n",
    "            dataset.append(per_line_dict)\n",
    "            used_sentences.add(sentence)\n",
    "            welfare_count += 1\n",
    "\n",
    "    # Then, add sentences from other categories\n",
    "    while len(dataset) < total_limit:\n",
    "        for category, sentences in balanced_dataset.items():\n",
    "            if len(dataset) >= total_limit:\n",
    "                break\n",
    "            if category != 'Environmental Protection' and category !=\"Sustainability: Positive\":\n",
    "                for key, value in super_set.items():\n",
    "                    if category in value:\n",
    "                        super_label = key\n",
    "\n",
    "                category_limit = min(len(sentences), category_limits[category])\n",
    "\n",
    "                limit = min(100, category_limit)\n",
    "\n",
    "                for sentence in sentences:\n",
    "                    if limit == 0 or len(dataset) >= total_limit:\n",
    "                        break\n",
    "\n",
    "                    if sentence not in used_sentences:\n",
    "                        per_line_dict = {\n",
    "                            \"sentence\": sentence,\n",
    "                            \"detailed_label\": category,\n",
    "                            \"general_label\": super_label\n",
    "                        }\n",
    "                        dataset.append(per_line_dict)\n",
    "                        used_sentences.add(sentence)\n",
    "                        limit -= 1\n",
    "                        category_limits[category] += 100\n",
    "\n",
    "    return dataset, welfare_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d91ecea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences in the dataset: 56000\n",
      "Sentences with 'Welfare and Quality of Life' label: 5600\n",
      "{'Welfare and Quality of Life': 9926, 'Economy': 10814, 'Fabric of Society': 13668, 'Social Groups': 3273, 'External Relations': 6903, 'Freedom and Democracy': 6335, 'Political System': 5081}\n",
      "56000\n",
      "115\n",
      "{'Environmental Protection': 5600, 'Welfare State Expansion': 700, 'Nationalisation': 700, 'Multiculturalism: Positive': 700, 'Agriculture and Farmers: Positive': 700, 'Incentives: Positive': 700, 'Market Regulation': 700, 'Economic Orthodoxy': 700, 'Technology and Infrastructure: Positive': 700, 'Equality: Positive': 700, 'Culture: Positive': 700, 'Military: Positive': 700, 'Freedom and Human Rights': 700, 'Law and Order: Positive': 700, 'Internationalism: Positive': 700, 'Education Expansion': 700, 'Political Authority: Party Competence': 700, 'Decentralization': 700, 'Free Market Economy': 700, 'Governmental and Administrative Efficiency': 700, 'Civic Mindedness General: Positive': 700, 'Law and Order: Negative': 700, 'Non-economic Demographic Groups': 700, 'Human Rights': 700, 'Political Corruption': 700, 'Traditional Morality: Negative': 700, 'Constitutionalism: Negative': 700, 'European Community/Union: Positive': 700, 'Economic Planning': 700, 'Political Authority': 700, 'Economic Growth: Positive': 700, 'Democracy General: Positive': 700, 'Economic Goals': 700, 'Anti-Growth Economy: Positive': 700, 'Middle Class and Professional Groups': 700, 'Traditional Morality: Positive': 700, 'National Way of Life: Immigration: Negative': 700, 'Multiculturalism General: Positive': 700, 'National Way of Life General: Positive': 700, 'National Way of Life: Immigration: Positive': 700, 'National Way of Life: Positive': 700, 'Direct Democracy: Positive': 700, 'National Way of Life General: Negative': 700, 'Welfare State Limitation': 700, 'Underprivileged Minority Groups': 700, 'Democracy': 700, 'Freedom': 700, 'Constitutionalism: Positive': 700, 'Multiculturalism: Negative': 645, 'Education Limitation': 515, 'Multiculturalism: Immigrants Assimilation': 407, 'Protectionism: Positive': 600, 'Military: Negative': 600, 'European Community/Union: Negative': 600, 'Anti-Imperialism: Foreign Financial Influence': 600, 'Civic Mindedness: Positive': 600, 'Protectionism: Negative': 600, 'Corporatism/Mixed Economy': 600, 'Centralisation': 600, 'Political Authority: Strong government': 371, 'Keynesian Demand Management': 600, 'Agriculture and Farmers: Negative': 182, 'Internationalism: Negative': 600, 'Multiculturalism General: Negative': 600, 'Foreign Special Relationships: Positive': 600, 'Controlled Economy': 600, 'Property-Restitution: Positive': 25, 'Private-Public Mix in Welfare: Positive': 227, 'Peace': 600, 'Political Authority: Personal Competence': 347, 'Anti-Imperialism': 442, 'Foreign Special Relationships: Negative': 600, 'Civic Mindedness: Bottom-Up Activism': 569, 'Multiculturalism: Immigrants Diversity': 600, 'Cyprus Issue': 472, 'Multiculturalism: Indigenous rights: Positive': 496, 'Privatisation: Negative': 16, 'Transition: Pre-Democratic Elites: Negative': 134, 'Russia/USSR/CIS: Positive': 26, 'Marxist Analysis': 600, 'National Way of Life: Negative': 600, 'General Crisis': 58, 'Representative Democracy: Positive': 594, 'Democracy General: Negative': 122, 'Independence: Positive': 42, 'War Participants: Positive': 142, 'Transition: Rehabilitation and Compensation': 46, 'Minorities Abroad: Positive': 78, 'Control of Economy: Negative': 126, 'Multiculturalism: Indigenous rights: Negative': 41, 'Private-Public Mix in Culture: Positive': 36, 'Communist: Negative': 46, 'Rights of Nations: Positive': 1, 'Transition: Pre-Democratic Elites: Positive': 1, 'Public Situation: Negative': 9, 'National Security: Positive': 175, 'Mixed Economy: Positive': 25, 'SFR Yugoslavia: Positive': 52, 'Private-Public Mix in Education: Positive': 47, 'Political Coalitions: Positive': 18, 'Restrictive Citizenship: Positive': 6, 'Refugees: Positive': 71, 'Russia/USSR/CIS: Negative': 7, 'Transition to Democracy': 13, 'Western States: Positive': 22, 'Publicly-Owned Industry: Positive': 12, 'Socialist Property: Positive': 3, 'Property-Restitution: Negative': 5, 'Nordic Council: Positive': 4, 'Rehabilitation and Compensation: Positive': 8, 'Eastern European Countries: Positive': 7, 'Cultural Autonomy: Positive': 5, 'Communist: Positive': 1, 'Social Ownership: Positive': 2, 'Private-Public Mix in Social Justice: Positive': 1}\n"
     ]
    }
   ],
   "source": [
    "\"Experiment 1\"\n",
    "total_limit = 56000\n",
    "desired_percentage = 0.10\n",
    "\n",
    "dataset, welfare_count = create_custom_dataset(train_dataset, total_limit, desired_percentage)\n",
    "\n",
    "print(\"Total sentences in the dataset:\", len(dataset))\n",
    "print(\"Sentences with 'Welfare and Quality of Life' label:\", welfare_count)\n",
    "\n",
    "# Usage example:\n",
    "# Assuming you have the 'dataset' variable containing the dataset obtained from the create_custom_dataset function\n",
    "# Replace this with the actual dataset you want to count.\n",
    "count_dataset = calculate_dataset_counts(dataset)\n",
    "print(count_dataset[\"general\"])\n",
    "print(sum(count_dataset[\"general\"].values()))\n",
    "print(len(count_dataset[\"detailed\"].keys()))\n",
    "print(count_dataset[\"detailed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebe0125",
   "metadata": {},
   "source": [
    "# RoBerta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49afe225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokens\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "226eee6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>detailed_label</th>\n",
       "      <th>general_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55489</th>\n",
       "      <td>In the field of spatial planning, the Fourth ...</td>\n",
       "      <td>Welfare State Limitation</td>\n",
       "      <td>Welfare and Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46767</th>\n",
       "      <td>At the heart of the European project are valu...</td>\n",
       "      <td>Human Rights</td>\n",
       "      <td>Freedom and Democracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8038</th>\n",
       "      <td>Promotion of respect for difference and the f...</td>\n",
       "      <td>Traditional Morality: Negative</td>\n",
       "      <td>Fabric of Society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15552</th>\n",
       "      <td>12. Strategic and unequivocal determination t...</td>\n",
       "      <td>Military: Positive</td>\n",
       "      <td>External Relations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27575</th>\n",
       "      <td>and giving, at the same time, a progressive r...</td>\n",
       "      <td>Military: Negative</td>\n",
       "      <td>External Relations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9911</th>\n",
       "      <td>No admission regulations will be set up for A...</td>\n",
       "      <td>Underprivileged Minority Groups</td>\n",
       "      <td>Social Groups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27168</th>\n",
       "      <td>Language skills and adaptation to Dutch livin...</td>\n",
       "      <td>Multiculturalism: Negative</td>\n",
       "      <td>Fabric of Society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25836</th>\n",
       "      <td>Such a family is the basis of the state, beca...</td>\n",
       "      <td>Traditional Morality: Positive</td>\n",
       "      <td>Fabric of Society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35612</th>\n",
       "      <td>4. Relationship between the companies.</td>\n",
       "      <td>Corporatism/Mixed Economy</td>\n",
       "      <td>Economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18799</th>\n",
       "      <td>Indeed, that additional pension fund is a big ...</td>\n",
       "      <td>Welfare State Limitation</td>\n",
       "      <td>Welfare and Quality of Life</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55999 rows Ã 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  \\\n",
       "55489   In the field of spatial planning, the Fourth ...   \n",
       "46767   At the heart of the European project are valu...   \n",
       "8038    Promotion of respect for difference and the f...   \n",
       "15552   12. Strategic and unequivocal determination t...   \n",
       "27575   and giving, at the same time, a progressive r...   \n",
       "...                                                  ...   \n",
       "9911    No admission regulations will be set up for A...   \n",
       "27168   Language skills and adaptation to Dutch livin...   \n",
       "25836   Such a family is the basis of the state, beca...   \n",
       "35612             4. Relationship between the companies.   \n",
       "18799  Indeed, that additional pension fund is a big ...   \n",
       "\n",
       "                        detailed_label                general_label  \n",
       "55489         Welfare State Limitation  Welfare and Quality of Life  \n",
       "46767                     Human Rights        Freedom and Democracy  \n",
       "8038    Traditional Morality: Negative            Fabric of Society  \n",
       "15552               Military: Positive           External Relations  \n",
       "27575               Military: Negative           External Relations  \n",
       "...                                ...                          ...  \n",
       "9911   Underprivileged Minority Groups                Social Groups  \n",
       "27168       Multiculturalism: Negative            Fabric of Society  \n",
       "25836   Traditional Morality: Positive            Fabric of Society  \n",
       "35612        Corporatism/Mixed Economy                      Economy  \n",
       "18799         Welfare State Limitation  Welfare and Quality of Life  \n",
       "\n",
       "[55999 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.DataFrame(data=(dataset))\n",
    "dataframe=shuffle(dataframe).dropna()\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b6ec85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences=list(dataframe[\"sentence\"])\n",
    "train_labels=[]\n",
    "for s in list(dataframe[\"detailed_label\"]):\n",
    "    if s=='Environmental Protection':\n",
    "        number=1\n",
    "    else:\n",
    "        number=0\n",
    "    train_labels.append(number)\n",
    "len(train_sentences)==len(train_labels)\n",
    "\n",
    "train_sentences_cleaned=[]\n",
    "for s in list(dataframe[\"sentence\"]):\n",
    "    cleaned=clean_text(s)\n",
    "    train_sentences_cleaned.append(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62bdc231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  135\n",
      "min:  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'The distribution of sequence length, when the percentage of Welfare sentences is: 10.0%')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenize the text feature \n",
    "tokenized_feature_raw = tokenizer.batch_encode_plus(\n",
    "                            # Sentences to encode\n",
    "                            train_sentences_cleaned, \n",
    "                            # Add '[CLS]' and '[SEP]'\n",
    "                            add_special_tokens = True      \n",
    "                   )\n",
    "# collect tokenized sentence length \n",
    "token_sentence_length = [len(x) for x in tokenized_feature_raw['input_ids']]\n",
    "print('max: ', max(token_sentence_length))\n",
    "print('min: ', min(token_sentence_length))\n",
    "# plot the distribution\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.hist(token_sentence_length, rwidth = 0.9)\n",
    "plt.xlabel('Sequence Length', fontsize = 18)\n",
    "plt.ylabel('Number of Samples', fontsize = 18)\n",
    "plt.xticks(fontsize = 14)\n",
    "plt.yticks(fontsize = 14)\n",
    "plt.title(\"The distribution of sequence length, when the percentage of Welfare sentences is: \"+str(desired_percentage*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49e63e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize features \n",
    "MAX_LEN = 135\n",
    "tokenized_feature = tokenizer.batch_encode_plus(\n",
    "                            # Sentences to encode\n",
    "                            train_sentences_cleaned, \n",
    "                            # Add '[CLS]' and '[SEP]'\n",
    "                            add_special_tokens = True,\n",
    "                            # Add empty tokens if len(text)<MAX_LEN\n",
    "                            padding = 'max_length',\n",
    "                            # Truncate all sentences to max length\n",
    "                            truncation=True,\n",
    "                            # Set the maximum length\n",
    "                            max_length = MAX_LEN, \n",
    "                            # Return attention mask\n",
    "                            return_attention_mask = True,\n",
    "                            # Return pytorch tensors\n",
    "                            return_tensors = 'pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "361641ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 80% for training and 20% for validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_inputs, validation_inputs, train_labels, validation_labels, train_masks, validation_masks = train_test_split(tokenized_feature['input_ids'], \n",
    "                                                                                                             train_labels,\n",
    "                                                                                                                    tokenized_feature['attention_mask'],\n",
    "                                                                                                      random_state=42, test_size=0.2, stratify=train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "329cf7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load base package for the tasks from pytorch\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "# define batch_size\n",
    "batch_size = 16\n",
    "# Create the DataLoader for our training set\n",
    "train_data = TensorDataset(train_inputs, train_masks, torch.tensor(train_labels))\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "# Create the DataLoader for our test set\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, torch.tensor(validation_labels))\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d468d2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# BertForSequenceClassification\n",
    "from transformers import XLMRobertaForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained(\n",
    "    \"xlm-roberta-base\", \n",
    "    # Specify number of classes\n",
    "    num_labels = len(set(train_labels)), \n",
    "    # Whether the model returns attentions weights\n",
    "    output_attentions = False,\n",
    "    # Whether the model returns all hidden-states \n",
    "    output_hidden_states = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73091f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 250002. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(250002, 768, padding_idx=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Receive the full size of the new word\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1a73d782",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/yabdul/.local/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Optimizer & Learning Rate Scheduler\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, \n",
    "                  eps = 1e-8 \n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a3043c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of training epochs\n",
    "epochs = 3\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "# Create the learning rate scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f366a34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaForSequenceClassification(\n",
       "  (roberta): XLMRobertaModel(\n",
       "    (embeddings): XLMRobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): XLMRobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): XLMRobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tell pytorch to run this model on GPU\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "23de45ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ebc3e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "import time\n",
    "import datetime\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "torch.cuda.empty_cache()\n",
    "# start training from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c83f4751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 3 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.20\n",
      "  Training epcoh took: 0:12:44\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.95\n",
      "\n",
      "======== Epoch 2 / 3 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.16\n",
      "  Training epcoh took: 0:12:25\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.94\n",
      "\n",
      "======== Epoch 3 / 3 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.14\n",
      "  Training epcoh took: 0:12:25\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.95\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:41:41 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    # Perform one full pass over the training set.\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the device using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)        \n",
    "        loss = output.loss\n",
    "        total_train_loss += loss.item()\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    t0 = time.time()\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    best_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "            output= model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "        loss = output.loss\n",
    "        total_eval_loss += loss.item()\n",
    "        # Move logits and labels to CPU if we are using GPU\n",
    "        logits = output.logits\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    if avg_val_accuracy > best_eval_accuracy:\n",
    "        torch.save(model, 'SustainabilityExperiment')\n",
    "        best_eval_accuracy = avg_val_accuracy\n",
    "    #print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    #print(\"  Validation took: {:}\".format(validation_time))\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "063c2b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('SustainabilityExperiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574c6b8b",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d0bae313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Now test the model on another unseen test sets--------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>detailed_label</th>\n",
       "      <th>general_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9101</th>\n",
       "      <td>The Bloc QuÃ©bÃ©cois is committed to continuing...</td>\n",
       "      <td>Multiculturalism: Positive</td>\n",
       "      <td>Fabric of Society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62694</th>\n",
       "      <td>the firm fight against organized crime and co...</td>\n",
       "      <td>Political Corruption</td>\n",
       "      <td>Political System</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19585</th>\n",
       "      <td>Use digitization in road traffic, introduce A...</td>\n",
       "      <td>Technology and Infrastructure: Positive</td>\n",
       "      <td>Economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10931</th>\n",
       "      <td>Small Farming Scheme.</td>\n",
       "      <td>Agriculture and Farmers: Positive</td>\n",
       "      <td>Social Groups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70965</th>\n",
       "      <td>The knowledge and resources for large-scale us...</td>\n",
       "      <td>Economic Goals</td>\n",
       "      <td>Economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21773</th>\n",
       "      <td>Construction of the extremely important cogene...</td>\n",
       "      <td>Technology and Infrastructure: Positive</td>\n",
       "      <td>Economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3031</th>\n",
       "      <td>Grants per child up to 3 years of â¬60 per mon...</td>\n",
       "      <td>Welfare State Expansion</td>\n",
       "      <td>Welfare and Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69120</th>\n",
       "      <td>Protect the sources and the independence of e...</td>\n",
       "      <td>Democracy General: Positive</td>\n",
       "      <td>Freedom and Democracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60485</th>\n",
       "      <td>The practical meaning of legalization or non-...</td>\n",
       "      <td>Law and Order: Negative</td>\n",
       "      <td>Fabric of Society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15899</th>\n",
       "      <td>Improve market transparency through public pri...</td>\n",
       "      <td>Market Regulation</td>\n",
       "      <td>Economy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>83276 rows Ã 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  \\\n",
       "9101    The Bloc QuÃ©bÃ©cois is committed to continuing...   \n",
       "62694   the firm fight against organized crime and co...   \n",
       "19585   Use digitization in road traffic, introduce A...   \n",
       "10931                              Small Farming Scheme.   \n",
       "70965  The knowledge and resources for large-scale us...   \n",
       "...                                                  ...   \n",
       "21773  Construction of the extremely important cogene...   \n",
       "3031    Grants per child up to 3 years of â¬60 per mon...   \n",
       "69120   Protect the sources and the independence of e...   \n",
       "60485   The practical meaning of legalization or non-...   \n",
       "15899  Improve market transparency through public pri...   \n",
       "\n",
       "                                detailed_label                general_label  \n",
       "9101                Multiculturalism: Positive            Fabric of Society  \n",
       "62694                     Political Corruption             Political System  \n",
       "19585  Technology and Infrastructure: Positive                      Economy  \n",
       "10931        Agriculture and Farmers: Positive                Social Groups  \n",
       "70965                           Economic Goals                      Economy  \n",
       "...                                        ...                          ...  \n",
       "21773  Technology and Infrastructure: Positive                      Economy  \n",
       "3031                   Welfare State Expansion  Welfare and Quality of Life  \n",
       "69120              Democracy General: Positive        Freedom and Democracy  \n",
       "60485                  Law and Order: Negative            Fabric of Society  \n",
       "15899                        Market Regulation                      Economy  \n",
       "\n",
       "[83276 rows x 3 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"-----Now test the model on another unseen test sets--------\")\n",
    "test_dataframe=[]\n",
    "for k,v in test_dataset.items():\n",
    "    for key, value in super_set.items():\n",
    "        if k in value:\n",
    "            super_label = key\n",
    "    for s in v:\n",
    "        if k!=\"Sustainability: Positive\":\n",
    "            per_line_dict = {}\n",
    "            per_line_dict[\"sentence\"] = s\n",
    "            per_line_dict[\"detailed_label\"] = k\n",
    "            per_line_dict[\"general_label\"] = super_label\n",
    "            test_dataframe.append(per_line_dict)\n",
    "\n",
    "test_dataframe = pd.DataFrame(data=(test_dataframe))\n",
    "test_dataframe=shuffle(test_dataframe).dropna()\n",
    "test_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6aea2740",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences_cleaned=[]\n",
    "for s in list(test_dataframe[\"sentence\"]):\n",
    "    cleaned=clean_text(s)\n",
    "    test_sentences_cleaned.append(cleaned)\n",
    "\n",
    "test_labels_numbers=[]\n",
    "for s in list(test_dataframe[\"detailed_label\"]):\n",
    "    if s=='Environmental Protection':\n",
    "        number=1\n",
    "    else:\n",
    "        number=0\n",
    "    test_labels_numbers.append(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c14491a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_sentences_cleaned)==len(test_labels_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a0bae036",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83276"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_sentences_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4ec1a2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  151\n",
      "min:  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Test set.The distribution of sequence length, when the percentage of Welfare sentences is: 10.0%')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABLMAAAH8CAYAAAAqtO18AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAAsTAAALEwEAmpwYAABM3klEQVR4nO3dd7gkVZ3/8fcHUECCIhJEiQZAQBGH1UFRUcdlDauAu6iooKuYUFh1FdRVDCi6gmL6CSZwFBO6rgEFXCUIyAq7ZMQAg6SBAYcoKuH7+6OqmZ6mb+iZe+dOOe/X8/TT3XVOVX2r+nTf298+51SqCkmSJEmSJKkLVprpACRJkiRJkqTJMpklSZIkSZKkzjCZJUmSJEmSpM4wmSVJkiRJkqTOMJklSZIkSZKkzjCZJUmSJEmSpM4wmSVJWmJJDk7y1Wna9j5JftH3/LYkW0zRtt+Z5Avt482SVJJVpmjbm7SxrjwV2xthvxskOTXJrUkOW5b7Xp4lmZfkWTOw3yltV+Psp5I8cjr3Mc6+T07y6pnYtxaX5PVJrms/e9adxv0cneSDy3q/aiTZOcmlMx2HJC0PTGZJ0jRo/7Hv3e5Jckff872WYHvT8qVxMGE0pHxKj2NpVNWaVXXZeHWSPD3JVZPY1oeqakrO52CypKr+0MZ691RsfwT7AjcAa1fVW5fxvld4M5U0W1amM3HdFYOJnOVFkvsBhwPPbj97bhwoPyHJO/qeP6xNgg5btuFU7bcLllXSeapU1WlVteXSbifJLkl+nuTmJPOGlG/Wlv8pya/H+2xLsmqSLyW5Jcn8JG/pK9s4yS+T/HHwR5YkP04ya2mPRdKKy2SWJE2D9h/7NatqTeAPwPP7ln1tpuObrL+V4+jXlS8tS2BT4OKqqpkORJopf8Pv7/FsAKwGXDRG+anAU/uePxX49ZBlv62q+VO433GtoK/V8uJ24EvAv41R/nXg/4B1gXcBxyVZb4y6BwOPovkbtAvw9iS7tmUHAccAmwMv7CWvkuwJXF5VZy/9oUhaUZnMkqRlKMlKSQ5M8vskNyb5VpIHt2WrJflqu/ymJL9qh44dAuwMfLrtEfXpIdsdum5b9sAkX0xybZKrk3wwycpJtgY+B8xut3vTEh7W/ZN8pR3edlH/L61JNkrynSQLklye5M3jnJt1k3y//XX3f4BHDJTfO5wqyXOSXNzu8+okb0uyBvBjYKO+3mMbtT1KjmvPzy3APmP0MnlVkmva8/S2vv0ODqu5t/dXkrnAJsAP2v29ffCX/jaG77e/TP8uyWv6tnVw2waGnr8h52in9rW9ub3fqRcjsDfNl4jbhv2KPuyc9ZU9L8m5bds5I8lj+8oen+R/2/W+meQbvfORIT37Bl6nVZN8LMkf0gxF+lyS1fvPY5K3Jrm+Pe+v7NvO6kkOS3JFe7y/6Fv3SW2cNyU5L8nTxzpnA7GN9/7rvW57t/HekORdA/Eck2Rhkkva13rMdtC3272GbW+COF+Z5Ad9z3+b5Nt9z69Msn3fKs9q69yU5DNJ0lf3VW28C9P00Nm0r6ySvG6sdfvq7Qq8E9izPb7z+oo3TXJ62z5OTPKQvvUm/Tql6dl2UNtGFyb5cpLV+srHa6PzkrwjyfnA7UlWSfKUvn1fmWSftu4Stckk+wJ7seg99oN2ea893drGvltfXCu3bfiGNJ9/+2Xxz4ahn81jnJ9Vk3wizWfUNe3jVZM8GugNO7spyc+GrH4q8OQkvf/7dwY+AcwaWHZqu6+tkpyU5jPr0iT/PCSeoftNckR7vm9Jck6SnfvWGfZZPMo5+LskZ7fbvi7J4X1lY7a1ND2bPzBGOz217xhuSzK7XWeJ3zdJXtOu22sTO7TLx/x7ON6xDZyDxXoft+3+6nZflyZ55rD1BlXV/1TVXOA+vZ3b13YH4L1VdUdVfQe4ANhjjM3tDXygqhZW1SXA54F92rLNgZ9V1c3Ar4AtkqwNHEjzmSJJS66qvHnz5s3bNN6AecCz2sf7A78EHg6sChwJfL0tey3wA+ABwMrAE2iGjAGcDLx6nH2Mt+5/tvtZA1gf+B/gtW3ZPsAvRj2OvmUHA38GntPu98PAL9uylYBzgPcA9we2oPnH+e/H2P43gG+1cW4LXN0fG1DAI9vH1wI7t4/XAXZoHz8duGpIjHcCL2xjWr1d9tW2fLN2219v970dsKDvNTsa+GDf9hbbx+B56dveKu3zU4HP0vRg2L7d9jMmOn9Dzs+DgYXAy4FVgJe0z9cdFueQ9cc6Z48Hrgee2Mawd3tMq7av2xXAvwL3A17UnssPjtV+Bl6njwPfb2Nfi6aNfrjvPN4FvL/d9nOAPwHrtOWfoWn3D2vj2qmN6WHAjW39lYA57fP1lvL913vdPk/TRh4H/AXYui0/FDilPXcPB86fZDsYur0J3mtbADe1x7dR+xpc1Ve2EFip73z/EHgQTUJtAbBrW/YC4HfA1jRt5t3AGQOv1dB1h8R0MO17pm/ZycDvgUe3x3gycGhbtiSv04XAxjTt5XQWtbMx22jfuue2665O00PkVpr3yP1oepdsPwVt8mgG3mPAP7Wv0UrAnjQ9Xh7alr0OuJimvawD/JTFPxvG/Gwecn7eT9N21wfWA86gSSDAwGfOkHVXBe4AHt8+v5CmHZ0+sOwVbSxXAq+kaTOPpxm+/JjBczBsv8DL2vO9CvBWYD6w2jifxaOcgzOBl7eP1wSeNJm2xvjtdNgxLPH7pm0PVwM7AgEeSdMex/17ONaxDTkHT2fRZ8GW7Wu1Ud+xPKJ9/BTgpkl81jwLmDewbDfgkoFlnwY+NWT9ddrzsUHfshcBF7SP/wPYrz1XvwW2AY4A9p4oNm/evHmb6GbPLElatl4HvKuqrqqqv9D8c/+i9pf6O2m+BDyyqu6uqnOq6pZJbnfouml6Zz0HOKCqbq+q62m+zL14Co/pF1V1fDVzRM2l+dIOzT/z61XV+6vqr9XMd/X5Yftuf4nfA3hPG+eFNEMTxnIn8Jgka1fza/D/ThDjmVX1vaq6p6ruGKPO+9p9XwB8meaL8FJJsjHwZOAdVfXnqjoX+ALNl8aesc7foOfSDAOaW1V3VdXXaYYKPX+S4Yx1zvYFjqyqs9q2cwxN0uVJ7e1+wCeq6s6qOo7m1/XJHHvabf9rVf2xqm4FPsTir/+dwPvbbR8P3AZs2fYWeRWwf1Vd3cZ1RvueeRlwfHvO7qmqk4Czadr5RMZ7//W8r5reCOcB57Ho9fhn4EPtubsK+ORkzsM42xtT+165lSb5+VTgBOCaJFsBTwNOq6p7+lY5tKpuqqo/AD9v1+sd74er6pKquovm/G/f38tknHUn68tV9Zv2ffWtvvWX5HX6dFVdWVV/BA5h0XtwvDba88l23TuAlwI/raqvt23rxqo6d2na5FgBV9W3q+qa9hi/SfOF/e/a4n8Gjmjb20KahCjQXLCB0T6b92rjur6qFgDvo0lsT6ht62cBT03TE/GBbRs7rW/ZY2iStc+jSW58uf2c+T/gOzRJmsns66vt+b6rqg6jSaT1n797P4uBtUc8B3cCj0zykKq6rap+2S6fTFsbq50OszTvm1cDH62qX1Xjd1V1BRP/PRzr2MZzN835fUyS+1XVvKr6PUBV/aKqHjSJbQyzJnDzwLKbaZK/w+r2yofV/TBNr79TaH7UuT/wWJperMemuWjJfksYp6QVnMksSVq2NgX+sx2acBNwCc0/pBvQJDJOAL7RDiP5aJoJdidjrHU3pUlGXNu3zyNpfgGfKv1zrPwJWK1NDmxKM+Tvpr59v5PmWAetR/ML+JV9y64YZ5970HxRuSLJKb2hIeO4coLywTpX0PS2WFobAb0vzf3bfljf87HO37BtDZ6TwW2NZ6xztinw1oHXaeN2fxsBV1dVDexzMtaj6Sl4Tt92f9Iu77mx/bLY8yeaL0cPoenJ9vsh290U+KeBeJ8CPHQSMY33/usZfD16X9Y2YvE2Mpk2Nd72JnIKTS+Mp7aPT6ZJZD2tfT6ZfWwKHNF3vH+k6S0yXvubbHyT2feor9NY78Hx2uiwdTdmeNtZmjY5VJJXZNHwx5toepX2hrCN12ZG/WwefP+P+hnVmzdrZ5oeWQC/6Ft2ZZt02RR44sC53guY1MTwaYZ8X5JmaPBNwANZdD5g6c7Bv9D0rvp1mmHWz+vbzkRtbZR2vjTvm7Ha3kR/D8c6tjFV1e+AA2iS8tenGQI+FX+3bqNJNPZbmybBPqxur/w+dduk8Z5V9TiaHlmfAt5EM8zwQpqeYa9LM+2BJI3EiRcladm6EnhVVZ0+Rvn7gPcl2Qw4nmZOki/SdOMfU1XdOca6x9P0YHjIwBe0e1ddgmOYrCtpJnh91CTqLqAZ3rMxTW8jaIZvDFVVvwJe0Cbs9qP5pX1jxj6eyRzn4L6vaR/fTvMFuGfwS914274GeHCStfoSWpvQDEMZ1TU0X4j6bULzZXxC45yzK4FDquqQwXWSPA14WJL0JbQ2YdGXtcXOTRa/EtoNNEObtqmqUY/3Bprhl4+g6c3U70pgblW95j5rTWzM91/7vhnPtTTDxS5un288UD7V76VTaHrdbU7TM+QmmqTCbJohP5PRe22n4mINox7fkrxO/ee0/z04ZhsdI74rWdQ7qt/StMnBfdD21Pk88EyaHkd3JzmXJvEBi9pMT//xXcn4n82Deu//3mTr/ednMk6l6XE0j6ZHFjRJrS+0y3pzR10JnFJVc0bYNgBp5sd6O835uKiq7kmykEXnA+77Ok36HFTVb4GXtD03d6eZlHxdlu4zYVi7Xpr3zZUMzPfYt3zMv4djHVtV3T7ezqrqWODYdh6qI4GPMMkee+O4iGZuq/6/W48Djh2y/4VJrm3LT+qrO+yiAPvSDKO/MMl2wMer6q9JLqAZ3n/JUsYtaQVjzyxJWrY+BxzSG66QZL0kL2gf75JkuzRD7m6hGXbQG0p0Hc0cG0ONtW5VXQucCByWZO00E2A/ok1S9Lb78CT3n4Zj/R/g1jQT1K6eZjLkbZPsOFixmiF23wUOTvKAJI+hmRdn2LHeP8leSR7YJvFuYfHztG6SBy5BvP/e7nsbmvlivtkuPxd4TpIHt8maAwbWG/O1qaoraea2+XCaSfofS/ML/ODk85NxPPDoJC9NM8H1njRDg3440YoTnLPP0/wy/sQ01kjy3CRr0czjchfw5iT3S7I7iycJzgO2SbJ9msm6D+479nvabX88yfptHA9L8vcTxduu+yXg8DSTJq+cZHaSVWnO3fOT/H27fLU0kyI/fPytAuO8/ybhW8BBSdZJ8jCahGC/cd+jg9qYx0sQnQLsAqxezbDG04BdaYYT/98kd/O5NuZt2n0+MMmkhosNcR2wWRZNGD6RJXmd3pjk4WmGvb2LRe/B8droMF+jmRT/n9v3yrpJtl+aNtkafI3XoEmGLGi39Uqanlk93wL2b/fxIOAdvYJJfDYP+jrw7rbNPoRm7qVRPkfOpJm36GW0yax26OOCdlkvmfVDms+Zl7fv+fsl2TGT6zmzFs3nxQJglSTv4b49fO416jlI8rIk67Wv403t4ntYus+EBe02+l/XpXnffAF4W5IntG31ke3nzbh/D8c5tjEl2TLJM9rPxT/TJGrHXadv3ZXaz+z7NU+zWtr/A6rqNzR/997bLt+NZmjgd8bY3Fdo2uY6aYZCv4ZmbrX+/a0PvJFFfyMuB3ZJsiYwiyET0UvSRExmSdKydQTN5MMnJrmVZkLfJ7ZlGwLH0SQaLqH5Mju3b70Xpbmy0rC5esZb9xU081RcTDNx9HEsGn7xM5pfUOcnuQEgyTuT/HhpD7RNUD2PZi6Ry2l6RXyBZtjJMPvRDNWYT/OP8JfH2fzLgXlproj1OpoeK1TVr2m+9F2WZijHKEMuTqGZ9Pe/gY9V1Ynt8rk0SZt5NF+8vjmw3odp/pG/KX1XCOzzEpqJea+hmez4vVX10xHiAqCqbqQ5n2+lmdz47cDzquqGSW5irHN2Ns2Xj0/TtI/f0V6Jqqr+StNLYB+aoTZ70iQdezH9hmZi6p/SzBW02JUNab68/w74ZbvfnzLO/EMD3kZzBa1ftfv+CM2k51fSTND8TpovolfSXF5+Mv/TjPf+m8j7gato2vJPad5Hf+krn6gdDNqYJtE5VHtub2NR4uEWmi98p7fvrQlV1X/SnLdvtOf/QuAfJrPuEL2rKd6YZKI56ljC1+lYmvfYZTS9/z7YbmvMNjrGvv9AM6T2rTRt51wWzVW2NG3yizTzE92U5HtVdTFwGE2i6Dqa3iX9vf4+3x7P+TQJyONpkj2912+8z+ZBH6SZB+p8mvfF/7bLJqXt4XNOu78L+4pOoxnWd2pb71bg2TRzOV1D83n8EZq5mSZyAk1P0d/QDIP8MxMPxx3lHOwKXJTkNpr38ourmY9uiT8TqupPNPOznd6+rk9amvdNVX273d6xNEPtvgc8eBJ/D4ce2wS7W5VmHrYbaF6n9YGDoOkl125rLE+lSX4dT9PL7w6attrzYpokU2+utxdVM1cbaX4Y6e959V6a9+sVNH9H/6OqBnsMf4xmzrdeTB8GnkHzWv2gfY9L0kiy+DQYkiRJY0tyNM3VtN4907HMpCSvp/nCOVZPmonW/wLw7ao6YWoj66Yk82iu2DpyorcrkvwD8LmqGhwuLEmSRmTPLEmSpAkkeWiSJ7fDc7ak6fXzn0u6vap6tYmsv23tcLLntEMdH0bTg2WJ24wkSVrEZJYkSdLE7k8zwfKtNMNz/4vmUvPSWEJzYY6FNMMML6GZ60qSJC0lhxlKkiRJkiSpM2asZ1aSg5PUwG1+X3naOtckuSPJyb2rivTVWSfJ3CQ3t7e57dVi+utsl+SUdhtXJ3lPkgzU2SPJxUn+0t7vNq0HL0mSJEmSpCUy08MML6W5Yknvtl1f2dtp5qN4E7AjcD1wUha/DPOxwA40VwDZtX3cu3oXSdYGTqK5wsyOwP40Vzd5S1+d2TRXpvoazRVGvgZ8O8lkr24kSZIkSZKkZWTGhhkmOZjmMq/bDikLzeWAP11Vh7TLVqdJaL2tqo5MsjXNZXyfUlWnt3WeQnOJ4a2q6tL2SkMfATboXd42ybuB1wMPr6pK8k2aS+bO6dv/T4EFVfWSiY7jIQ95SG222WZLfB4kSZIkSZK0uHPOOeeGqlpvWNkqyzqYAVskuQb4C3AW8M6qugzYHNgQOLFXsaruSHIqsBPNBKyzgduAM/q2dzpwe1vn0rbOab1EVusE4APAZsDlbZ1PDcR1ArDfZA5gs8024+yzz55MVUmSJEmSJE1CkivGKpvJYYZnAfvQDA98DU3y6owk67aPoRke2O+6vrINaXpP3du1rH18/UCdYdtgEnU2ZAxJ9k1ydpKzFyxYMFY1SZIkSZIkTbEZ65lVVT/uf57kl8BlwN7AL2ckqEmqqqOAowBmzZrl5SAlSZIkSZKWkZmeAP5eVXUbcBHwKKB3VcMNBqpt0Fc2H1iv/8qE7eP1B+oM2waTqDMfSZIkSZIkLVeWm2RWktWArYBraeaymg/MGSjfmUVzZJ0JrEkz51XPbGCNgTo7t+v2zKGZXH5eX505LG4Oi8/FJUmSJEmSpOXAjCWzknwsydOSbJ7kicBxNImoY9q5rz4BvCPJ7km2BY6mmfD9WICqugT4CXBkktlJZtNMDP/Dqrq03c2xwJ+Ao5Nsm2R34EDg8L65to4AnpHkwCRbJTkI2KXdvyRJkiRJkpYjM3k1w4cDXwceAiygmSfrSVXVm63+o8DqwGeAdWgmjH92Vd3at42X0lyJ8IT2+ffpuwphVd2cZE67jbOBhcBhwOF9dc5I8mLgg8D7gd8De1bVWVN6tJIkSZIkSVpq6bsYoJbArFmz6uyzz57pMCRJkiRJkv5mJDmnqmYNK1tu5sySJEmSJEmSJmIyS5IkSZIkSZ1hMkuSJEmSJEmdYTJLkiRJkiRJnWEyS5IkSZIkSZ1hMkuSJEmSJEmdYTJLkiRJkiRJnWEyS5IkSZIkSZ1hMkuSJEmSJEmdYTJLkiRJkiRJnWEyS5IkSZIkSZ1hMkuSJEmSJEmdscpMB6Dlx2YH/mimQ1ihzDv0uTMdgiRJkiRJnWPPLEmSJEmSJHWGySxJkiRJkiR1hsksSZIkSZIkdYbJLEmSJEmSJHWGySxJkiRJkiR1hsksSZIkSZIkdYbJLEmSJEmSJHWGySxJkiRJkiR1hsksSZIkSZIkdYbJLEmSJEmSJHWGySxJkiRJkiR1hsksSZIkSZIkdYbJLEmSJEmSJHWGySxJkiRJkiR1hsksSZIkSZIkdYbJLEmSJEmSJHWGySxJkiRJkiR1hsksSZIkSZIkdYbJLEmSJEmSJHWGySxJkiRJkiR1hsksSZIkSZIkdYbJLEmSJEmSJHWGySxJkiRJkiR1hsksSZIkSZIkdYbJLEmSJEmSJHWGySxJkiRJkiR1hsksSZIkSZIkdYbJLEmSJEmSJHWGySxJkiRJkiR1hsksSZIkSZIkdYbJLEmSJEmSJHWGySxJkiRJkiR1hsksSZIkSZIkdYbJLEmSJEmSJHWGySxJkiRJkiR1hsksSZIkSZIkdYbJLEmSJEmSJHWGySxJkiRJkiR1hsksSZIkSZIkdYbJLEmSJEmSJHWGySxJkiRJkiR1hsksSZIkSZIkdYbJLEmSJEmSJHWGySxJkiRJkiR1hsksSZIkSZIkdYbJLEmSJEmSJHWGySxJkiRJkiR1hsksSZIkSZIkdYbJLEmSJEmSJHWGySxJkiRJkiR1hsksSZIkSZIkdYbJLEmSJEmSJHWGySxJkiRJkiR1hsksSZIkSZIkdYbJLEmSJEmSJHWGySxJkiRJkiR1hsksSZIkSZIkdYbJLEmSJEmSJHWGySxJkiRJkiR1hsksSZIkSZIkdYbJLEmSJEmSJHWGySxJkiRJkiR1xnKTzEpyUJJK8um+ZUlycJJrktyR5OQk2wyst06SuUlubm9zkzxooM52SU5pt3F1kvckyUCdPZJcnOQv7f1u03rAkiRJkiRJGtlykcxK8iRgX+D8gaK3A28F3gTsCFwPnJRkrb46xwI7ALu2tx2AuX3bXhs4Cbiu3cb+wL8Bb+mrMxv4JvA1YPv2/ttJnjhVxyhJkiRJkqSlN+PJrCQPpEkevQpY2Lc8wAHAoVX1naq6ENgbWAt4aVtna5oE1r5VdWZVnQm8Fnheki3bTe0FPADYu6ourKrjgI8Ab+nrnXUA8POqOqSqLqmqQ4CT2+WSJEmSJElaTsx4Mgs4Cjiuqn4+sHxzYEPgxN6CqroDOBXYqV00G7gNOKNvvdOB2wfqnNau23MCsBGwWV+dE1ncCX3bkCRJkiRJ0nJgRpNZSV4DPBJ495DiDdv76waWX9dXtiGwoKqqV9g+vn6gzrBtMIk6GyJJkiRJkqTlxiozteN2GOCHgKdU1Z0zFceSSLIvzRxfbLLJJjMcjSRJkiRJ0opjJntmzQYeAlyU5K4kdwFPA97QPr6xrbfBwHobAPPbx/OB9fqvTNg+Xn+gzrBtMIk68xmiqo6qqllVNWu99dYb/yglSZIkSZI0ZWYymfU9YDuaqwf2bmcD32gf/4YmmTSnt0KS1YCdWTRH1pnAmjSJsZ7ZwBoDdXZu1+2ZA1wDzOurM4fFzWHxubgkSZIkSZI0w2ZsmGFV3QTc1L8sye3AH9srF5LkE8A7k/yaJrn1bpoJ349tt3FJkp8AR7ZD/wCOBH5YVZe2z48F3gscneSDwKOBA4H39c21dQRwapIDaZJsuwG7AE+Z2qOWJEmSJEnS0pixZNYkfRRYHfgMsA5wFvDsqrq1r85LgU/RXH0Q4PvAfr3Cqro5yZx2G2cDC4HDgMP76pyR5MXAB4H3A78H9qyqs6bpuCRJkiRJkrQElqtkVlU9feB5AQe3t7HWWQi8bILtXgA8dYI6xwHHTS5SSZIkSZIkzYSZnDNLkiRJkiRJGonJLEmSJEmSJHWGySxJkiRJkiR1hsksSZIkSZIkdYbJLEmSJEmSJHWGySxJkiRJkiR1hsksSZIkSZIkdYbJLEmSJEmSJHWGySxJkiRJkiR1hsksSZIkSZIkdYbJLEmSJEmSJHWGySxJkiRJkiR1hsksSZIkSZIkdYbJLEmSJEmSJHWGySxJkiRJkiR1hsksSZIkSZIkdYbJLEmSJEmSJHWGySxJkiRJkiR1hsksSZIkSZIkdYbJLEmSJEmSJHWGySxJkiRJkiR1hsksSZIkSZIkdYbJLEmSJEmSJHWGySxJkiRJkiR1hsksSZIkSZIkdYbJLEmSJEmSJHWGySxJkiRJkiR1hsksSZIkSZIkdYbJLEmSJEmSJHWGySxJkiRJkiR1hsksSZIkSZIkdYbJLEmSJEmSJHWGySxJkiRJkiR1hsksSZIkSZIkdYbJLEmSJEmSJHXGKkuzcpJVgBcADwZ+UFXzpyQqSZIkSZIkaYhJ98xK8tEkv+p7HuCnwLeAI4ELkjxi6kOUJEmSJEmSGqMMM9wVOK3v+fOBpwL/Aby0XXbgFMUlSZIkSZIk3ccowww3Bn7b9/z5wOVVdSBAkm2AvaYwNkmSJEmSJGkxo/TMuj9wV9/zXWiGGfZcBjx0KoKSJEmSJEmShhklmXUlMBvu7YW1BXBKX/n6wG1TF5okSZIkSZK0uFGGGX4D+Pck6wPbALcAx/eVPx74/RTGJkmSJEmSJC1mlJ5ZHwaOpumdVcArquomgCQPBP4R+O8pjk+SJEmSJEm616R7ZlXVX4B/aW+DbqWZL+tPUxSXJEmSJEmSdB+jDDMcU1XdA9w8FduSJEmSJEmSxjLKMEOSbJzkS0muSvLXJM9ol6/XLt9xesKUJEmSJEmSRkhmJdkcOBvYA7gIWLlXVlULgFnAq6c6QEmSJEmSJKlnlGGGhwD3ANsCdwDXD5QfDzx/iuKSJEmSJEmS7mOUYYbPAj5bVVfSXM1w0BXAw6ckKkmSJEmSJGmIUZJZawPXjlN+f6ZoQnlJkiRJkiRpmFGSWVcC24xT/iTgd0sXjiRJkiRJkjS2UZJZ3wVelWTbvmUFkGQP4J+Ab01hbJIkSZIkSdJiRklmHQJcBZwFfJUmkXVgkjNpkljnAYdNeYSSJEmSJElSa9LJrKq6BZgNfAGYBQSYA2wJfBbYpar+PB1BSpIkSZIkSTDihO1tQmt/YP8k69EktBZU1bCrG0qSJEmSJElTaomvPlhVC6YyEEmSJEmSJGkiYyazkmyyJBusqj8seTiSJEmSJEnS2MbrmTWP9mqFI1p5yUKRJEmSJEmSxjdeMuv9LFkyS5IkSZIkSZoWYyazqurgZRiHJEmSJEmSNKGVZjoASZIkSZIkabJGvpphkr8DdgO2aBddBnyvqs6aysAkSZIkSZKkQZNOZiVZGTgK2AfIQPHbk3wFeHVV3T114UmSJEmSJEmLjDLM8N3AK4H/AnYCHtTengx8H3hFW0eSJEmSJEmaFqMks14FnFRVu1fVL6vqlvZ2ZlXtBvysrSNJkiRJkiRNi1GSWevT9MAay/faOpIkSZIkSdK0GCWZ9Rtgw3HKH9rWkSRJkiRJkqbFKMmsDwNvTPK4wYIkjwfeAHxoqgKTJEmSJEmSBk36aobAo4HLgbOTnAj8ul2+NTAHOA/YMsl7+tapqvrAlEQqSZIkSZKkFd4oyayD+x7/Q3vrt0N761eAySxJkiRJkiRNiVGSWZtPWxSSJEmSJEnSJEw6mVVVV0xnIJIkSZIkSdJERpkAXpIkSZIkSZpRowwzJMmmwL7Ao4B1gQxUqap65hTFJkmSJEmSJC1m0smsJP8IfBu4H3ALsHC6gpIkSZIkSZKGGaVn1keAK4HdquqCaYpHkiRJkiRJGtMoc2ZtBnxyqhJZSd6Y5Pwkt7S3M5M8t688SQ5Ock2SO5KcnGSbgW2sk2Rukpvb29wkDxqos12SU9ptXJ3kPUkyUGePJBcn+Ut7v9tUHKMkSZIkSZKm1ijJrMuBVadw31cB7wB2AGYBPwO+l+SxbfnbgbcCbwJ2BK4HTkqyVt82jm3X37W97QDM7RUmWRs4Cbiu3cb+wL8Bb+mrMxv4JvA1YPv2/ttJnjiFxypJkiRJkqQpMEoy6xPAq5OsMRU7rqr/qqofV9Xvquo3VfUu4FZgdttz6gDg0Kr6TlVdCOwNrAW8FCDJ1jQJrH2r6syqOhN4LfC8JFu2u9kLeACwd1VdWFXH0QyXfEtf76wDgJ9X1SFVdUlVHQKc3C6XJEmSJEnScmTSc2ZV1VFtT6eLkhwDzAPuHlLvK6MGkWRl4J+ANYEzgM2BDYET+7Z7R5JTgZ2AI4HZwG1t/Z7TgdvbOpe2dU6rqjv66pwAfIBm2OTlbZ1PDYR0ArDfqMchSZIkSZKk6TXK1Qw3AHYHNgH+fYxqBUw6mZVkO+BMYDWaxNRuVXVBkp3aKtcNrHId8LD28YbAgqqqe3deVUmub8t6da4aso1e2eXt/bD9bMgYkuwL7AuwySabjHeIkiRJkiRJmkKjXM3wczTzTn0cOA1YOAX7v5RmnqoHAi8Cjkny9CnY7rSqqqOAowBmzZpVE1SXJEmSJEnSFBklmfVM4IiqettU7byq/gr8rn16TpIdgX8FDmmXbQD8oW+VDYD57eP5wHpJ0uud1c6Dtf5AnQ0GdrtBX9l4deYjSZIkSZKk5cooE8D/hUWJp+myEs0VEy+nSSbN6RUkWQ3YmUVzZJ1JM8fW7L71ZwNrDNTZuV23Zw5wDc2cX706c1jcHBafi0uSJEmSJEnLgVGSWT/ivkmfJZbk0CQ7J9ksyXZJPgw8Hfha29PqE8A7kuyeZFvgaJp5tY4FqKpLgJ8ARyaZnWQ2zcTwP6yqS9vdHAv8CTg6ybZJdgcOBA7vm2vrCOAZSQ5MslWSg4Bd2v1LkiRJkiRpOTJKMustwMZJPpnkEe2QvqWxIfBVmnmz/ptmPq5/qKoft+UfpZmf6zPA2cBDgWdX1a1923gpcB7N1QdPaB+/vFdYVTfTJOA2arfxGeAw4PC+OmcALwb2Ac4HXgHsWVVnLeXxSZIkSZIkaYql72KA41dM7qG5WuF4qqpGmYer82bNmlVnn332TIcxJTY78EczHcIKZd6hz53pECRJkiRJWi4lOaeqZg0rGyXx9BUmTmZJkiRJkiRJ02bSyayq2mca45AkSZIkSZImNMqcWZIkSZIkSdKMWqL5rZKsCTyIIcmwqvrDUsYkSZIkSZIkDTVSMivJi4F3A1uPU23lpYpIkiRJkiRJGsOkhxkmeSFwLE0C7EggwNeBbwN3AucA75/6ECVJkiRJkqTGKD2z3gZcAjwBWBN4HfClqvpZkm2B04FDpj5EacW22YE/mukQVjjzDn3uTIcgSZIkSRrDKBPAPxY4pqr+DNzTLlsZoKouBI4CDpra8CRJkiRJkqRFRklmrQzc2D6+o71/YF/5pcC2UxGUJEmSJEmSNMwoyayrgE0BquoO4HqaIYc9WwK3T11okiRJkiRJ0uJGmTPrDOBZwHva598HDkhyB01S7I3AD6Y2PEmSJEmSJGmRUZJZnwV2S7J62zPrXcDfAQe35RfRTBIvSZIkSZIkTYtJJ7Oq6lfAr/qeLwC2T/JY4G7gkqq6Z6z1JUmSJEmSpKU1Ss+soarq/KkIRJIkSZIkSZrIEiezkmwBvBh4GM0Qwy+3ww8lSZIkSZKkaTFuMivJvwBvBuZU1fV9y+cA3wUeAAQo4HVJdqqq26YxXkmSJEmSJK3AVpqg/HnArQOJrABH0iSyPgz8I3A0sC3wr9MTpiRJkiRJkjRxMutxwC8Glu0EbAbMrap3V9UPq+pfgJ8DL5zyCCVJkiRJkqTWRMms9YDLBpY9mWZY4bcGlh8PPHKK4pIkSZIkSZLuY6Jk1l3A/QeW7djenzmw/EZg1akISpIkSZIkSRpmomTWPJphhQAkWRnYGfhtVS0cqLsucMOURidJkiRJkiT1mSiZ9R3gRUn2S/IY4FCaoYffHVL374DLpzg+SZIkSZIk6V6rTFD+SeAVwBHt8wBXAof1V0ryQOC5wOFTHaAkSZIkSZLUM24yq6puSfIEYF+ayd1/D3yhqm4aqLo18GXgG9MRpCRJkiRJkgQT98yiqm5loCfWkDq/BH45VUFJkiRJkiRJw0w0Z5YkSZIkSZK03DCZJUmSJEmSpM4wmSVJkiRJkqTOMJklSZIkSZKkzjCZJUmSJEmSpM4YM5mV5LIk/9j3/D1Jtl02YUmSJEmSJEn3NV7PrE2AtfqeHww8dlqjkSRJkiRJksYxXjLramC7gWU1jbFIkiRJkiRJ41plnLL/At6eZFfgj+2ydyd5zTjrVFU9c8qikyRJkiRJkvqMl8x6B7AQeBawKU2vrPWAByyDuCRJkiRJkqT7GDOZVVV3AO9tbyS5Bzigqo5dRrFJkiRJkiRJixlvzqxBrwTOmK5AJEmSJEmSpImMN8xwMVV1TO9xknWBzdunl1fVjVMdmCRJkiRJkjRolJ5ZJHlcklOA64Gz2tv1SU5O8tjpCFCSJEmSJEnqmXTPrCTbAr8AVqO50uFFbdE2wPOB05LsVFUXjbEJSZIkSZIkaalMOpkFvB+4E3hyVZ3fX9Amuk5t6+wxdeFJkiRJkiRJi4wyzPCpwGcGE1kAVXUh8FngaVMVmCRJkiRJkjRolGTWGsD8ccqvbetIkiRJkiRJ02KUZNZlwPPGKX9eW0eSJEmSJEmaFqMks74C/H2SY5Nsk2Tl9rZtkq8BzwaOnpYoJUmSJEmSJEabAP5jwA7Ai4E9gXva5SsBAb4FHDal0UmSJEmSJEl9Jp3Mqqq7gT2TfAF4IbB5W3QZ8L2q+unUhydJkiRJkiQtMkrPLACq6iTgpGmIRZIkSZIkSRrXKHNmSZIkSZIkSTPKZJYkSZIkSZI6w2SWJEmSJEmSOsNkliRJkiRJkjrDZJYkSZIkSZI6Y1LJrCSrJ3lFkidOd0CSJEmSJEnSWCbbM+svwOeBx09jLJIkSZIkSdK4JpXMqqp7gCuBtac3HEmSJEmSJGlso8yZdQzw8iSrTlcwkiRJkiRJ0nhWGaHuGcDuwLlJPgv8FvjTYKWqOnWKYpMkSZIkSZIWM0oy66S+x0cANVCedtnKSxuUJEmSJEmSNMwoyaxXTlsUkiRJkiRJ0iRMOplVVcdMZyCSJEmSJEnSREaZAF6SJEmSJEmaUSMls5JsnORLSa5K8tckz2iXr9cu33F6wpQkSZIkSZJGSGYl2Rw4G9gDuIi+id6ragEwC3j1VAcoSZIkSZIk9YwyAfwhwD3AtsAdwPUD5ccDz5+iuCRJkiRJkqT7GGWY4bOAz1bVlUANKb8CePiURCVJkiRJkiQNMUoya23g2nHK789oPb0kSZIkSZKkkYySzLoS2Gac8icBv1u6cCRJkiRJkqSxjZLM+i7wqiTb9i0rgCR7AP8EfGsKY5MkSZIkSZIWM0oy6xDgKuAs4Ks0iawDk5xJk8Q6DzhsyiOUJEmSJEmSWpNOZlXVLcBs4AvALCDAHGBL4LPALlX15+kIUpIkSZIkSYIRJ2xvE1r7A/snWY8mobWgqoZd3VCSJEmSJEmaUkt89cGqWjCVgUiSJEmSJEkTGTmZleSfgd2ALdpFlwH/WVVO/i5JkiRJkqRpNelkVpI1gO8Bz6AZXnhTW7Qj8M9JXgv8Y1XdPsUxSpIkSZIkScDoVzN8JvApYKOqenBVPRjYqF22S1tnUpIclORXSW5JsiDJD5JsO1AnSQ5Ock2SO5KcnGSbgTrrJJmb5Ob2NjfJgwbqbJfklHYbVyd5T5IM1NkjycVJ/tLe7zbCuZEkSZIkSdIyMEoya0/g21V1QFXN7y2sqvlVdQDwnbbOZD2d5iqIO9H09roL+GmSB/fVeTvwVuBNND3ArgdOSrJWX51jgR2AXdvbDsDcXmGStYGTgOvabewP/Bvwlr46s4FvAl8Dtm/vv53kiSMcjyRJkiRJkqbZKHNmrQ38fJzynwHPmezGqurv+58neTlwM/Bk4Adtz6kDgEOr6jttnb1pElovBY5MsjVNAuspVXVmW+e1wGlJtqyqS4G9gAcAe1fVHcCFSbYC3pLk8PZKjAcAP6+qXs+yQ5Ls0i5/yWSPSZIkSZIkSdNrlJ5Z5wOPGqf8UcAFSxHLWm08C9vnmwMbAif2KrTJqFNpenMBzAZuA87o287pwO0DdU5r1+05gWZ45GZ9dU5kcSf0bUOSJEmSJEnLgVGSWe8GXpPk+YMFSV4AvBp451LEcgRwLnBm+3zD9v66gXrX9ZVtCCxoe1cB0D6+fqDOsG0wiTobIkmSJEmSpOXGmMMMk3xpyOLLge8luRS4pF22NbAlTa+svWiGG44kyeHAU2iGC9496vrLWpJ9gX0BNtlkkxmORpIkSZIkacUx3pxZ+4xTtlV76/dYYDvgX0YJIMnHgRcDu1TVZX1FvUnmNwD+0Ld8g76y+cB6SdLrndXOtbX+QJ0NBna7QV/ZeHXmM0RVHQUcBTBr1qwaVkeSJEmSJElTb8xhhlW10hLcVh5l50mOoJlg/RlV9euB4stpkklz+uqvBuzMojmyzgTWpJnzqmc2sMZAnZ3bdXvmANcA8/rqzGFxc1h8Li5JkiRJkiTNsFHmzJpSST4DvJLmyoQLk2zY3taEe+e++gTwjiS7J9kWOJpmwvdj2zqXAD+hubLh7CSzgSOBH7ZXMqSt+yfg6CTbJtkdOBA4vG+urSOAZyQ5MMlWSQ4Cdmn3L0mSJEmSpOXEjCWzgDfQXMHwv4Fr+25v66vzUeDjwGeAs4GHAs+uqlv76rwUOI/m6oMntI9f3iusqptpellt1G7jM8BhwOF9dc6gGeq4D81VG18B7FlVZ03VwUqSJEmSJGnpjTdn1n0k2Ql4I/AoYF0gA1Wqqh4xmW1V1eC6w+oUcHB7G6vOQuBlE2znAuCpE9Q5DjhuopgkSZIkSZI0cyadzEryGuBzwF+BS1l8UnZJkiRJkiRp2o3SM+udwLnA31fVDdMTjiRJkiRJkjS2UebM2gD4ooksSZIkSZIkzZRRklmXAOtMVyCSJEmSJEnSREZJZh0CvCHJRtMVjCRJkiRJkjSeSc+ZVVXfTfIA4OIk/wXMA+6+b7X6wBTGJ0mSJEmSJN1rlKsZPhp4P7A28PIxqhVgMkuSJEmSJEnTYpSrGX4WWB/YHzgNWDgtEUmSJEmSJEljGCWZNRv4j6r61HQFI0mSJEmSJI1nlAngbwYWTFcgkiRJkiRJ0kRGSWZ9C9h9ugKRJEmSJEmSJjLKMMMjgWOSfA/4JHA5972aIVX1h6kJTZIkSZIkSVrcKMmsi2iuVjgLeP449VZeqogkSZIkSZKkMYySzHo/TTJLkiRJkiRJmhGTTmZV1cHTGIckSZIkSZI0oVEmgJckSZIkSZJm1KR7ZiV56mTqVdWpSx6OJEmSJEmSNLZR5sw6mcnNmeUE8JIkSZIkSZoWoySzXjnG+o8A9gHmAUcufUiSJEmSJEnScKNMAH/MWGVJ/gP43ymJSJIkSZIkSRrDlEwAX1ULgS8Ab5+K7UmSJEmSJEnDTOXVDBcCW0zh9iRJkiRJkqTFTEkyK8lqwMuB+VOxPUmSJEmSJGmYSc+ZleRLYxQ9GJgNrAf821QEJUmSJEmSJA0zytUM9xlj+R+B3wD/WlXHLnVEkiRJkiRJ0hhGuZrhVM6vJUmSJEmSJI3MBJUkSZIkSZI6w2SWJEmSJEmSOmPcYYZJvj/i9qqqXrAU8UiSJEmSJEljmmjOrOeNuL1a0kAkSZIkSZKkiYw7zLCqVproBuwC/Kpd5dppj1iSJEmSJEkrrCWeMyvJtkl+BPwM2BL4d+BRUxWYJEmSJEmSNGiiYYb3kWRj4APAXsDdwCeBD1bVjVMcmyRJkiRJkrSYSSezkqwDvAt4A7Aq8HXg3VU1b3pCkyRJkiRJkhY3YTIryarAAcA7gAcBJwHvqKpzpzMwSZIkSZIkadC4c2Yl+Rfgd8CHgN8Dc6rq701kSZIkSZIkaSZM1DPr80ABZwPfAh6X5HHj1K+q+vhUBSdJkiRJkiT1m8ycWQF2bG8TKcBkliRJkiRJkqbFRMmsXZZJFJIkSZIkSdIkjJvMqqpTllUgkiRJkiRJ0kTGnQBekiRJkiRJWp6YzJIkSZIkSVJnmMySJEmSJElSZ5jMkiRJkiRJUmeYzJIkSZIkSVJnmMySJEmSJElSZ5jMkiRJkiRJUmeYzJIkSZIkSVJnmMySJEmSJElSZ5jMkiRJkiRJUmeYzJIkSZIkSVJnmMySJEmSJElSZ5jMkiRJkiRJUmeYzJIkSZIkSVJnmMySJEmSJElSZ5jMkiRJkiRJUmeYzJIkSZIkSVJnmMySJEmSJElSZ5jMkiRJkiRJUmeYzJIkSZIkSVJnmMySJEmSJElSZ5jMkiRJkiRJUmeYzJIkSZIkSVJnmMySJEmSJElSZ5jMkiRJkiRJUmeYzJIkSZIkSVJnmMySJEmSJElSZ5jMkiRJkiRJUmeYzJIkSZIkSVJnmMySJEmSJElSZ5jMkiRJkiRJUmeYzJIkSZIkSVJnmMySJEmSJElSZ5jMkiRJkiRJUmeYzJIkSZIkSVJnmMySJEmSJElSZ8xoMivJU5N8P8nVSSrJPgPlSXJwkmuS3JHk5CTbDNRZJ8ncJDe3t7lJHjRQZ7skp7TbuDrJe5JkoM4eSS5O8pf2frfpOm5JkiRJkiQtmZnumbUmcCGwP3DHkPK3A28F3gTsCFwPnJRkrb46xwI7ALu2tx2Aub3CJGsDJwHXtdvYH/g34C19dWYD3wS+Bmzf3n87yROn4BglSZIkSZI0RVaZyZ1X1fHA8QBJju4va3tOHQAcWlXfaZftTZPQeilwZJKtaRJYT6mqM9s6rwVOS7JlVV0K7AU8ANi7qu4ALkyyFfCWJIdXVbX7+XlVHdLu/pAku7TLXzJNhy9JkiRJkqQRzXTPrPFsDmwInNhb0CajTgV2ahfNBm4Dzuhb73Tg9oE6p7Xr9pwAbARs1lfnRBZ3Qt82JEmSJEmStBxYnpNZG7b31w0sv66vbENgQdu7CoD28fUDdYZtg0nU2ZAhkuyb5OwkZy9YsGAShyJJkiRJkqSpsDwns5ZbVXVUVc2qqlnrrbfeTIcjSZIkSZK0wliek1nz2/sNBpZv0Fc2H1iv/8qE7eP1B+oM2waTqDMfSZIkSZIkLTeW52TW5TTJpDm9BUlWA3Zm0RxZZ9JcEXF233qzgTUG6uzcrtszB7gGmNdXZw6Lm8Pic3FJkiRJkiRphs1oMivJmkm2T7J9G8sm7fNN2rmvPgG8I8nuSbYFjqaZ8P1YgKq6BPgJzZUNZyeZDRwJ/LC9kiFt3T8BRyfZNsnuwIHA4X1zbR0BPCPJgUm2SnIQsEu7f0mSJEmSJC0nZrpn1izg/9rb6sD72sfvb8s/Cnwc+AxwNvBQ4NlVdWvfNl4KnEdz9cET2scv7xVW1c00vaw2arfxGeAw4PC+OmcALwb2Ac4HXgHsWVVnTeXBSpIkSZIkaemsMpM7r6qTgYxTXsDB7W2sOguBl02wnwuAp05Q5zjguPHqSJIkSZIkaWbNdM8sSZIkSZIkadJMZkmSJEmSJKkzTGZJkiRJkiSpM0xmSZIkSZIkqTNMZkmSJEmSJKkzTGZJkiRJkiSpM0xmSZIkSZIkqTNMZkmSJEmSJKkzTGZJkiRJkiSpM0xmSZIkSZIkqTNMZkmSJEmSJKkzTGZJkiRJkiSpM0xmSZIkSZIkqTNMZkmSJEmSJKkzTGZJkiRJkiSpM0xmSZIkSZIkqTNMZkmSJEmSJKkzTGZJkiRJkiSpM0xmSZIkSZIkqTNMZkmSJEmSJKkzTGZJkiRJkiSpM0xmSZIkSZIkqTNMZkmSJEmSJKkzTGZJkiRJkiSpM0xmSZIkSZIkqTNMZkmSJEmSJKkzTGZJkiRJkiSpM0xmSZIkSZIkqTNMZkmSJEmSJKkzTGZJkiRJkiSpM0xmSZIkSZIkqTNMZkmSJEmSJKkzVpnpACSpqzY78EczHcIKZd6hz53pECRJkiQtB+yZJUmSJEmSpM4wmSVJkiRJkqTOMJklSZIkSZKkzjCZJUmSJEmSpM4wmSVJkiRJkqTOMJklSZIkSZKkzjCZJUmSJEmSpM4wmSVJkiRJkqTOMJklSZIkSZKkzjCZJUmSJEmSpM4wmSVJkiRJkqTOMJklSZIkSZKkzjCZJUmSJEmSpM4wmSVJkiRJkqTOMJklSZIkSZKkzjCZJUmSJEmSpM4wmSVJkiRJkqTOMJklSZIkSZKkzjCZJUmSJEmSpM4wmSVJkiRJkqTOMJklSZIkSZKkzjCZJUmSJEmSpM4wmSVJkiRJkqTOMJklSZIkSZKkzjCZJUmSJEmSpM4wmSVJkiRJkqTOMJklSZIkSZKkzjCZJUmSJEmSpM4wmSVJkiRJkqTOMJklSZIkSZKkzjCZJUmSJEmSpM4wmSVJkiRJkqTOMJklSZIkSZKkzjCZJUmSJEmSpM4wmSVJkiRJkqTOMJklSZIkSZKkzjCZJUmSJEmSpM4wmSVJkiRJkqTOWGWmA5AkaSptduCPZjqEFcq8Q5870yFIkiRpBWPPLEmSJEmSJHWGySxJkiRJkiR1hsksSZIkSZIkdYbJLEmSJEmSJHWGyaw+Sd6Q5PIkf05yTpKdZzomSZIkSZIkLWIyq5VkT+AI4EPA44EzgB8n2WRGA5MkSZIkSdK9VpnpAJYjbwGOrqrPt8/flGRX4PXAQTMXliRJfxs2O/BHMx3CCmXeoc+d6RAkSZKmhcksIMn9gScAHxsoOhHYadlHJEmStGyYZFy2TDJKkrT0UlUzHcOMS7IRcDXwtKo6tW/5e4C9qmrLgfr7Avu2T7cELl1WsQ7xEOCGGdy/ln+2EU2G7USTYTvRRGwjmgzbiSZiG9Fk2E7+9m1aVesNK7Bn1hKoqqOAo2Y6DoAkZ1fVrJmOQ8sv24gmw3aiybCdaCK2EU2G7UQTsY1oMmwnKzYngG/cANwNbDCwfANg/rIPR5IkSZIkScOYzAKq6q/AOcCcgaI5NFc1lCRJkiRJ0nLAYYaLHA7MTfI/wOnA64CNgM/NaFQTWy6GO2q5ZhvRZNhONBm2E03ENqLJsJ1oIrYRTYbtZAXmBPB9krwBeDvwUOBC4F/7J4SXJEmSJEnSzDKZJUmSJEmSpM5wzixJkiRJkiR1hsmsjkryhiSXJ/lzknOS7DzTMWnmJDkoya+S3JJkQZIfJNl2oE6SHJzkmiR3JDk5yTYzFbNmVttmKsmn+5bZRkSShyY5pv0s+XOSi5M8ra/cdrICS7Jykg/0/Q9yeZIPJlmlr45tZAWT5KlJvp/k6vZvyz4D5RO2iSTrJJmb5Ob2NjfJg5blcWh6jddOktwvyUeSnJ/k9iTXJjk2ySYD21g1yaeS3NDW+36Shy/zg9G0mOizZKDukW2dtw0st42sIExmdVCSPYEjgA8Bj6e54uKPBz/stUJ5OvBZYCfgGcBdwE+TPLivztuBtwJvAnYErgdOSrLWsg1VMy3Jk4B9gfMHimwjK7j2i+PpQIDnAlvTtIfr+6rZTlZs7wDeCLwZ2ArYv31+UF8d28iKZ02a+Wb3B+4YUj6ZNnEssAOwa3vbAZg7jTFr2RuvnTyA5jU/pL1/AbAx8JP+ZDnwCWAP4CXAzsDawA+TrDytkWtZmeizBIAkLwL+DrhmSPEnsI2sEJwzq4OSnAWcX1Wv6Vv2W+C4qjpo7DW1okiyJnAz8MKq+kGS0HzYf7qqDmnrrE7zz+TbqurImYtWy1KSBwL/C7waeC9wYVXtZxsRQJIPAU+rqiePUW47WcEl+SFwY1Xt3bfsGGDdqnqebURJbgP2q6qj2+cTtokkWwMXA0+pqtPbOk8BTgO2qqpLl/2RaDoNtpMx6jwGuAh4bFVd0P4PswB4ZVV9ra2zMXAF8A9VdcL0R65lZaw2kmRTms4czwJ+TPPZ8rG2zDayArFnVsckuT/wBODEgaITaXrlSABr0by/F7bPNwc2pK/dVNUdwKnYblY0R9Ekvn8+sNw2IoAXAmcl+WaS65Ocm6SX7ATbieAXwC5JtoJ7v2w+Azi+LbeNaNBk2sRs4DaaL6g9pwO3Y7tZka3d3vf+n30CcD8Wb0tXApdgO1khtL30vg58sKouGVLFNrICWWXiKlrOPARYGbhuYPl1NNlpCZphqOcCZ7bPN2zvh7Wbhy2jmDTDkrwGeCTwsiHFthEBbAG8Afg4cCiwPfCptuzT2E4EH6H5weTiJHfT/C95SFV9ti23jWjQZNrEhsCC6hsyUlWV5Pq+9bUCaX/APwz4QVVd1S7eELgbuGGg+nXYTlYU7wNuqKr/N0a5bWQFYjJL+huT5HDgKTRd9e+e6Xi0fEiyJc08e0+pqjtnOh4tt1YCzu4bsv5/SR5FMyfSp8deTSuQPYFXAC+lGf6zPXBEksur6oszGZikvw1t75uvAg8C/nFmo9HyIsnTgX1o/u5IDjPsoBtoss0bDCzfAJi/7MPR8iTJx2kmO3xGVV3WV9RrG7abFddsmp6dFyW5K8ldwNOAN7SPb2zr2UZWbNfSzFvT7xKgd4ERP0v0H8DHquobVXVBVc0FDmfRBPC2EQ2aTJuYD6zXN6S5N9fW+thuVih9w8geCzyzqm7sK55PM0LlIQOr+fmyYng68FDg2r7/ZTcFPpKk13vPNrICMZnVMVX1V+AcYM5A0RwWn2dAK5gkR7AokfXrgeLLaT7A5/TVX43mCh+2mxXD94DtaH7N6t3OBr7RPv4NthE1c9RsObDs0TQTp4KfJWquODbY6/duFv1PaRvRoMm0iTNprmI2u2+92cAa2G5WGEnuB3yTJpG1S1UNJh/OAe5k8bb0cJor79pO/vZ9lqZtbN93u4ZmaoRntnVsIysQhxl20+HA3CT/Q/PF43XARsDnZjQqzZgknwFeTjN588IkvTHht1XVbe28E58A3pnk1zSJi3fTTLZ67AyErGWsqm4CbupfluR24I9VdWH7/BPYRlZ0HwfOSPIumi8UjwfeDLwT7p3D5hPYTlZkPwAOTHI5zTDDxwNvAb4CtpEVVXsV5Ue2T1cCNkmyPc3fmD9M1Caq6pIkPwGOTLJvu50jgR96JcO/HeO1E5qkxLeBHYHnA9X3/+zNVXVHVd2c5IvAR9v51G6k+V50PvDTZXckmi4TfZbQXAW1v/6dwPze54RtZMWSvnkW1SFJ3gC8naar5YXAv1bVqTMblWZKkrHeyO+rqoPbOgHeC7wWWAc4C3hjL5GhFU+Sk4ELq2q/9rltRCR5Ls38alsCf6CZK+tTvYmZbScrtiRrAR8AdqMZAnYtTQ/P91fVn9s6tpEVTDuXzeBVcgGOqap9JtMmkqxDc8GJ3hxJ3wf2a3+M0d+A8doJcDBNL75hXllVR7fbWBX4GM28fasD/w28ob1inTpuos+SIfXnAZ+uqo/1LbONrCBMZkmSJEmSJKkznDNLkiRJkiRJnWEyS5IkSZIkSZ1hMkuSJEmSJEmdYTJLkiRJkiRJnWEyS5IkSZIkSZ1hMkuSJEmSJEmdYTJLkiRJK6Qk+ySpJE+f6VgkSdLkmcySJEmdlWSLJEcl+XWSPyVZmOSSJMck2WWm4/tbleTkJLfNdByTkWT7JAcn2WymY5EkSVNjlZkOQJIkaUkkmQWcAtwJfAW4CFgdeBTwbOBW4OczFqCWF9sD7wVOBubNZCCSJGlqmMySJEld9V7gAcD2VXXeYGGSDZd9SJIkSZpuDjOUJEld9SjgxmGJLICqmj+4LMmzkpyY5KYkf05yfpLXDVs/yWva4Yt/SfK7JAckeeXgHEtJjk5SY2yjkhw9ZPmeSX6R5NZ2eORZSV401vpJZic5JcntSW5M8oUkaw6pv2GSTya5rI37+iQnJZkzUO9RSeYmuTbJX5PMS/IfSdYYdhxLKo3XJzmnPc7bkvx8cAhoks3aYz04yfOS/Kp9fa5t47rPD7BJ9khyXlvvD0ne276+lWSfts7BwJfbVX7elg17TVZK8rYkv2/P22+S7D2V50KSJE0de2ZJkqSu+j2wZZLdq+q7E1VOsi/wOeCXwCHA7cAc4P8leURV/Vtf3QOAjwPnAe+k6QH2NuD6pQ06yQeBdwE/Af4duAfYDfh2kv2q6jMDq2wP/JAmKXMs8HTgX9r19u3b7mbA6cAGNMMuzwbWAJ4EPAs4qa33BOBnwE3AkcDVwOOANwNPTvK0qrpzaY+zNRd4CXBcG/+qwF7ASe3r9v2B+s8B3kDzOn0JeAHNeV8IfKjvWPcEvk7TBt4H3AXsDTx/YHvfBR5Kc54+BFzSLv/9QL0P0QxRPRL4C/B64Ogkv6uq05fkwCVJ0vRJ1dAfEiVJkpZrSWbTzJl1P+C3wC+AXwEnV9UlA3UfClwOfLeqXjpQdgSwH/CoqrosyYNoEjxXALOq6k9tvYcDv6ZJEO1SVSe3y48G9q6qDImxgGOqap/2+Q7AOcCHq+qdA3W/BzwDeFhV3dq3fgGzq+qsvro/opkXbJ2quq1ddjzwD8CuVXXCwLZXqqp72sfn0SSVduztp12+G03y55VVdfTgsQxs7+T23Nynd9iQ7b22qo7qW74KTUJxXWCLqqo2EXc58Cdgm6qa19YNcAGwblU9tG/9K2h+lN2qqha2y9cEzgc27z+GtpfWl+l7zfpi6ZWdCzyxqv7aLn8YcBlNe3nJeOdCkiQtew4zlCRJnVRVZwJPAI4BHgi8EvgscHGSU5Ns0Vf9RTQJnC8meUj/DfgBzf9Ez2rrPpumJ9Zneomsdn9XAV9byrD3oklOHTMkju8DawGzB9Y5sz+R1foZTTJnM4AkDwZ2BX4ymMhqY+8lsrYDHkvTw2vVgf3/gqa32rOX8hh7XkYzCf/3BvbzIJpzvhnNUNF+3+slstq4i2YS/w37hlU+AdgIOLqXyGrr3kbTo2tJfLaXyGq3dTXwmyHxSZKk5YDDDCVJUmdV1QXAPgBJNgWeBrwa2Bn4ryRPaJMUW7er/HSczW3Q3veSYL8eUufipQx5ayBjbHswjp7LhtS5sb1ft71/ZLvd/5vE/qEZmve+Se5/SW1Nk5y7bpw6G9AkjXomOtbbaHpeAVw6pO6wZZMx1n43XcLtSZKkaWQyS5Ik/U2oqiuArySZC5wGPBn4O5oeR70hgK8Arh1jE8MSGpPa9bCFwyYtb+MomuGAd4+xvYsGno9Vr7e9UfTqH0YzZ9cwC8dYPqoAC4CXjlPnwoHnU3msoxhrv9O5T0mStIRMZkmSpL8p7RxMZ9Eksx7WLv5te39DVY3XOwsWJbW2Av57oOwxQ+r/EZqhflX1x77lWwyp+1ua4YB/GJzXayn9jiZJtv0E9Xrn4e5JnIel9Vvg0cAve/N6TZF57f2WQ8qGLXOCWEmS/sY4Z5YkSeqkJHOG9X5KsjqL5n3qDQv8Fs1V6t7Xlg+u88Akq7ZPTwLuAN6Y5AF9dR7O8F5GvWFyzxpY/tYhdee29x9KsvKQOJZoiF+bRPsx8A9JBuPoTaQOzTDEC4HXDcwp1qu3Sjv/1lT4Cs3/mh8eVrikx0pzlcZrgX2SrNO3vTWB1w2p30ukTdVxSZKkGWbPLEmS1FUfB9ZN8n2aK979CdiYJuH0aOAr7ZxaVNVVSV4PfAG4pB2KeAWwHrAd8EKaXlfzqmphkn8HPgackeQrNBPCv46mt9HjB+L4OvAh4KgkW9H01NoVeMhgwFX1qyQHAwcD5yb5NnAN8FCaic2fA9x/Cc/HfsAZwI+THENz1cTVgSfS9GZ6R9tr7eU0E8ifn+RLNMMaH0Az79buwEHA0ZPY3/2SvHuMsu9W1XFJvgzs117F8YfADcDDaSa5fyTDe6+Nq6ruSvI2msn4/yfJF4G7aOZOu5FmTq3+3li/Au4B3tUmv24HLh8yqb4kSeoIk1mSJKmr3gK8AHgKsAfNVfJuBs4HPsJAQqaqvpzkN8DbgNe29W+gmTT834H5fXUPS3Jbu48PA1fSJLduBr40sN1bkjwHOBx4J01PoO/SXM3vPvNPVdX7kpwNvBk4AFgDuJ6mx9Sbl+hMNNu9PMms9lieQzM/2ELgPOCovnrnJnk8TdLqH2mSdLfSJLyO5r5DK8dyf+ADY5T9Dri4ql6V5OfAvu3+7k9znv+3fb5EqurYJHfSHOv7aCaZ/yLNa/9dmp51vbp/SPIq4B3A/wPuR3MFTJNZkiR1VJorHkuSJGkiSfYBvgzsUlUnz2w0GpTkrTRJx9lV9cuZjkeSJE0P58ySJElSpyS5/+CcY+2cWW+kGWr4vzMSmCRJWiYcZihJkqSu2YJmbrBvAJfTzDm2N818Wa+vqr/OZHCSJGl6mcySJElS1ywAfgnsBaxPMwH8BcCBVfWtmQxMkiRNP+fMkiRJkiRJUmc4Z5YkSZIkSZI6w2SWJEmSJEmSOsNkliRJkiRJkjrDZJYkSZIkSZI6w2SWJEmSJEmSOsNkliRJkiRJkjrj/wMB4Hfi7dqjAQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenize the text feature \n",
    "test_tokenized_feature = tokenizer.batch_encode_plus(\n",
    "                            # Sentences to encode\n",
    "                            test_sentences_cleaned, \n",
    "                            # Add '[CLS]' and '[SEP]'\n",
    "                            add_special_tokens = True      \n",
    "                   )\n",
    "# collect tokenized sentence length \n",
    "token_sentence_length = [len(x) for x in test_tokenized_feature['input_ids']]\n",
    "print('max: ', max(token_sentence_length))\n",
    "print('min: ', min(token_sentence_length))\n",
    "# plot the distribution\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.hist(token_sentence_length, rwidth = 0.9)\n",
    "plt.xlabel('Sequence Length', fontsize = 18)\n",
    "plt.ylabel('Number of Samples', fontsize = 18)\n",
    "plt.xticks(fontsize = 14)\n",
    "plt.yticks(fontsize = 14)\n",
    "plt.title(\"Test set.The distribution of sequence length, when the percentage of Welfare sentences is: \"+str(desired_percentage*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0dea8a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize features \n",
    "MAX_LEN = 151\n",
    "test_tokenized_feature = tokenizer.batch_encode_plus(\n",
    "                            # Sentences to encode\n",
    "                            test_sentences_cleaned, \n",
    "                            # Add '[CLS]' and '[SEP]'\n",
    "                            add_special_tokens = True,\n",
    "                            # Add empty tokens if len(text)<MAX_LEN\n",
    "                            padding = 'max_length',\n",
    "                            # Truncate all sentences to max length\n",
    "                            truncation=True,\n",
    "                            # Set the maximum length\n",
    "                            max_length = MAX_LEN, \n",
    "                            # Return attention mask\n",
    "                            return_attention_mask = True,\n",
    "                            # Return pytorch tensors\n",
    "                            return_tensors = 'pt'     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "09c8d26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataLoader for our test set\n",
    "validation_data = TensorDataset(test_tokenized_feature['input_ids'], test_tokenized_feature['attention_mask'], torch.tensor(test_labels_numbers))\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "245af2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time used is: 456.16 s\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "import numpy as np\n",
    "t0 = time.time()\n",
    "# model in validation mode\n",
    "model.eval()\n",
    "# save prediction\n",
    "predictions,true_labels =[],[]\n",
    "# evaluate data for one epoch\n",
    "for batch in validation_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    # validation\n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids,\n",
    "                        token_type_ids=None,\n",
    "                        attention_mask=b_input_mask)\n",
    "    # get output\n",
    "    logits = outputs[0]\n",
    "    # move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    final_prediction = np.argmax(logits, axis=-1).flatten()\n",
    "    predictions.append(final_prediction)\n",
    "    true_labels.append(label_ids)\n",
    "    \n",
    "print('total time used is: {0:.2f} s'.format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "17602d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert numeric label to string\n",
    "final_prediction_list = np.concatenate(predictions)\n",
    "len(final_prediction_list)==len(test_labels_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "51f50af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC Accuracy on Unseen Test Set: 0.94\n",
      "Linear SVC F1-Score on Unseen Test Set: 0.93\n",
      "Linear SVC Balanced Accuracy on Unseen Test Set: 0.84\n",
      "\n",
      "Linear SVC Classification Report on Unseen Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97     75801\n",
      "           1       0.63      0.73      0.68      7475\n",
      "\n",
      "    accuracy                           0.94     83276\n",
      "   macro avg       0.80      0.84      0.82     83276\n",
      "weighted avg       0.94      0.94      0.94     83276\n",
      "\n",
      "Linear SVC Confusion Matrix on Unseen Test Set:\n",
      "[[72580  3221]\n",
      " [ 2017  5458]]\n"
     ]
    }
   ],
   "source": [
    "# convert numeric label to string\n",
    "final_prediction_list = np.concatenate(predictions)\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(test_labels_numbers, final_prediction_list)\n",
    "\n",
    "# Evaluate F1-score\n",
    "#f1_score = f1_score(list(test_labels_numbers), list(final_prediction_list), average='weighted')\n",
    "\n",
    "# Evaluate balanced accuracy\n",
    "balanced_accuracy = balanced_accuracy_score(test_labels_numbers, final_prediction_list)\n",
    "\n",
    "\n",
    "# Print evaluation metrics for Linear SVC on the unseen test set\n",
    "print(\"Linear SVC Accuracy on Unseen Test Set:\", round(accuracy,2))\n",
    "print(\"Linear SVC F1-Score on Unseen Test Set:\", round(f1_score,2))\n",
    "print(\"Linear SVC Balanced Accuracy on Unseen Test Set:\", round(balanced_accuracy,2))\n",
    "print()\n",
    "\n",
    "# Print classification report and confusion matrix for Linear SVC on the unseen test set\n",
    "print(\"Linear SVC Classification Report on Unseen Test Set:\")\n",
    "print(classification_report(test_labels_numbers, final_prediction_list))\n",
    "\n",
    "print(\"Linear SVC Confusion Matrix on Unseen Test Set:\")\n",
    "print(confusion_matrix(test_labels_numbers, final_prediction_list))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

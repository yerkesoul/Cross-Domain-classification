{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80cd81b1",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79f916d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8214]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "import subprocess as sp\n",
    "import os\n",
    "def get_gpu_memory():\n",
    "    command = \"nvidia-smi --query-gpu=memory.free --format=csv\"\n",
    "    memory_free_info = sp.check_output(command.split()).decode('ascii').split('\\n')[:-1][1:]\n",
    "    memory_free_values = [int(x.split()[0]) for i, x in enumerate(memory_free_info)]\n",
    "    return memory_free_values\n",
    "\n",
    "get_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c20c53b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import json\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "with open('test_dataset.json', 'r') as fp:\n",
    "    test_dataset = json.load(fp)\n",
    "with open('train_dataset.json', 'r') as fp:\n",
    "    train_dataset = json.load(fp)\n",
    "f = open('/data/data_codebook.json')\n",
    "data_codebook = json.load(f)\n",
    "super_set={}\n",
    "for s in data_codebook:\n",
    "    if s[2]!=\"domain_name\":\n",
    "        if s[2] not in super_set:\n",
    "            super_set[s[2]]=[]\n",
    "        if s[5] not in super_set[s[2]]:\n",
    "            super_set[s[2]].append(s[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1536de84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
    "# import all the metrics we'll use later on\n",
    "from sklearn.metrics import precision_score,recall_score\n",
    "\n",
    "\n",
    "sw = stopwords.words('english')\n",
    "\n",
    "def clean_text(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", text) # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "\n",
    "    text = re.sub(r\"http\\S+\", \"\",text) #Removing URLs \n",
    "    #text = re.sub(r\"http\", \"\",text)\n",
    "    \n",
    "    html=re.compile(r'<.*?>') \n",
    "    \n",
    "    text = html.sub(r'',text) #Removing html tags\n",
    "    \n",
    "    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\" + '_'\n",
    "    for p in punctuations:\n",
    "        text = text.replace(p,'') #Removing punctuations\n",
    "        \n",
    "    text = [word.lower() for word in text.split() if word.lower() not in sw]\n",
    "    \n",
    "    text = \" \".join(text) #removing stopwords\n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text) #Removing emojis\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49afe225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokens\n",
    "from transformers import AutoTokenizer\n",
    "# load base package for the tasks from pytorch\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "import time\n",
    "import datetime\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34317d43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>detailed_label</th>\n",
       "      <th>general_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19264</th>\n",
       "      <td>Responsible fiscal policy</td>\n",
       "      <td>Technology and Infrastructure: Positive</td>\n",
       "      <td>Economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21288</th>\n",
       "      <td>We will increase the tonnage of the Croatian ...</td>\n",
       "      <td>Technology and Infrastructure: Positive</td>\n",
       "      <td>Economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61321</th>\n",
       "      <td>We prepared \"The Situation of the Elderly in ...</td>\n",
       "      <td>Non-economic Demographic Groups</td>\n",
       "      <td>Social Groups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54649</th>\n",
       "      <td>Extension of the requirement for environmenta...</td>\n",
       "      <td>Environmental Protection</td>\n",
       "      <td>Welfare and Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38279</th>\n",
       "      <td>Imposition of expulsion already by the crimin...</td>\n",
       "      <td>Law and Order: Positive</td>\n",
       "      <td>Fabric of Society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19393</th>\n",
       "      <td>Currently there are many open source projects...</td>\n",
       "      <td>Technology and Infrastructure: Positive</td>\n",
       "      <td>Economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37970</th>\n",
       "      <td>Deduction of personal and criminal responsibi...</td>\n",
       "      <td>Law and Order: Positive</td>\n",
       "      <td>Fabric of Society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22156</th>\n",
       "      <td>According to experts, Lithuanian research and...</td>\n",
       "      <td>Technology and Infrastructure: Positive</td>\n",
       "      <td>Economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6062</th>\n",
       "      <td>An enormous investment cycle and parallelism ...</td>\n",
       "      <td>Welfare State Expansion</td>\n",
       "      <td>Welfare and Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11857</th>\n",
       "      <td>Open Vld considers it opportune to introduce ...</td>\n",
       "      <td>Incentives: Positive</td>\n",
       "      <td>Economy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84860 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  \\\n",
       "19264                          Responsible fiscal policy   \n",
       "21288   We will increase the tonnage of the Croatian ...   \n",
       "61321   We prepared \"The Situation of the Elderly in ...   \n",
       "54649   Extension of the requirement for environmenta...   \n",
       "38279   Imposition of expulsion already by the crimin...   \n",
       "...                                                  ...   \n",
       "19393   Currently there are many open source projects...   \n",
       "37970   Deduction of personal and criminal responsibi...   \n",
       "22156   According to experts, Lithuanian research and...   \n",
       "6062    An enormous investment cycle and parallelism ...   \n",
       "11857   Open Vld considers it opportune to introduce ...   \n",
       "\n",
       "                                detailed_label                general_label  \n",
       "19264  Technology and Infrastructure: Positive                      Economy  \n",
       "21288  Technology and Infrastructure: Positive                      Economy  \n",
       "61321          Non-economic Demographic Groups                Social Groups  \n",
       "54649                 Environmental Protection  Welfare and Quality of Life  \n",
       "38279                  Law and Order: Positive            Fabric of Society  \n",
       "...                                        ...                          ...  \n",
       "19393  Technology and Infrastructure: Positive                      Economy  \n",
       "37970                  Law and Order: Positive            Fabric of Society  \n",
       "22156  Technology and Infrastructure: Positive                      Economy  \n",
       "6062                   Welfare State Expansion  Welfare and Quality of Life  \n",
       "11857                     Incentives: Positive                      Economy  \n",
       "\n",
       "[84860 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_manifesto_dataframe=[]\n",
    "for k,v in test_dataset.items():\n",
    "    for key, value in super_set.items():\n",
    "        if k in value:\n",
    "            super_label = key\n",
    "    for s in v:\n",
    "            per_line_dict = {}\n",
    "            per_line_dict[\"sentence\"] = s\n",
    "            per_line_dict[\"detailed_label\"] = k\n",
    "            per_line_dict[\"general_label\"] = super_label\n",
    "            test_manifesto_dataframe.append(per_line_dict)\n",
    "\n",
    "test_manifesto_dataframe = pd.DataFrame(data=(test_manifesto_dataframe))\n",
    "test_manifesto_dataframe=shuffle(test_manifesto_dataframe).dropna()\n",
    "test_manifesto_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65ffb00",
   "metadata": {},
   "source": [
    "# Transferability test: ClimateBert/Environmental_claims dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54abd423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, pipeline\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "import datasets\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "dataset_name = \"climatebert/environmental_claims\"\n",
    "# If you want to use your own data, simply load them as 🤗 Datasets dataset, see https://huggingface.co/docs/datasets/loading\n",
    "climatebert = datasets.load_dataset(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae807033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2117\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 265\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 265\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "climatebert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd96ba45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences once the train,validation and test sets of Climatebert dataset was combined: 2647\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "climatebert_dataset=[]\n",
    "for k,v in climatebert.items():\n",
    "    for sentence in v:\n",
    "        climatebert_dataset.append(sentence)\n",
    "print(\"Number of sentences once the train,validation and test sets of Climatebert dataset was combined:\",len(climatebert_dataset))\n",
    "climatebert_text_original=[]\n",
    "climatebert_text=[]\n",
    "climatebert_labels=[]\n",
    "for item in climatebert_dataset:\n",
    "    climatebert_text_original.append(item['text'])\n",
    "    cleaned_text=clean_text(item['text'])\n",
    "    climatebert_text.append(cleaned_text)\n",
    "    climatebert_labels.append(item[\"label\"])\n",
    "print(len(climatebert_text)==len(climatebert_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bf8b4cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  62\n",
      "min:  4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([  0., 100., 200., 300., 400., 500., 600., 700., 800.]),\n",
       " [Text(0, 0.0, '0'),\n",
       "  Text(0, 100.0, '100'),\n",
       "  Text(0, 200.0, '200'),\n",
       "  Text(0, 300.0, '300'),\n",
       "  Text(0, 400.0, '400'),\n",
       "  Text(0, 500.0, '500'),\n",
       "  Text(0, 600.0, '600'),\n",
       "  Text(0, 700.0, '700'),\n",
       "  Text(0, 800.0, '800')])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenize the text feature \n",
    "climatebert_tokenized_feature = tokenizer.batch_encode_plus(\n",
    "                            # Sentences to encode\n",
    "                            climatebert_text, \n",
    "                            # Add '[CLS]' and '[SEP]'\n",
    "                            add_special_tokens = True      \n",
    "                   )\n",
    "# collect tokenized sentence length \n",
    "token_sentence_length = [len(x) for x in climatebert_tokenized_feature['input_ids']]\n",
    "print('max: ', max(token_sentence_length))\n",
    "print('min: ', min(token_sentence_length))\n",
    "MAX_LEN = max(token_sentence_length)\n",
    "# plot the distribution\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.hist(token_sentence_length, rwidth = 0.9)\n",
    "plt.xlabel('Sequence Length', fontsize = 18)\n",
    "plt.ylabel('Number of Samples', fontsize = 18)\n",
    "plt.xticks(fontsize = 14)\n",
    "plt.yticks(fontsize = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f89b1e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD the model\n",
    "model = torch.load('Roberta_10percent_OneStep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5af7c7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "climatebert_tokenized_feature = tokenizer.batch_encode_plus(\n",
    "                            # Sentences to encode\n",
    "                            climatebert_text, \n",
    "                            # Add '[CLS]' and '[SEP]'\n",
    "                            add_special_tokens = True,\n",
    "                            # Add empty tokens if len(text)<MAX_LEN\n",
    "                            padding = 'max_length',\n",
    "                            # Truncate all sentences to max length\n",
    "                            truncation=True,\n",
    "                            # Set the maximum length\n",
    "                            max_length = MAX_LEN, \n",
    "                            # Return attention mask\n",
    "                            return_attention_mask = True,\n",
    "                            # Return pytorch tensors\n",
    "                            return_tensors = 'pt'    )\n",
    "\n",
    "\n",
    "batch_size=16\n",
    "# Create the DataLoader for the climatebert dataset\n",
    "climatebert_validation_data = TensorDataset(climatebert_tokenized_feature['input_ids'], climatebert_tokenized_feature['attention_mask'], torch.tensor(climatebert_labels))\n",
    "validation_sampler = SequentialSampler(climatebert_validation_data)\n",
    "climatebert_validation_dataloader = DataLoader(climatebert_validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cfebbc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time used is: 5.95 s\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "import numpy as np\n",
    "t0 = time.time()\n",
    "# model in validation mode\n",
    "model.eval()\n",
    "# save prediction\n",
    "predictions,true_labels =[],[]\n",
    "# evaluate data for one epoch\n",
    "for batch in climatebert_validation_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    # validation\n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids,\n",
    "                        token_type_ids=None,\n",
    "                        attention_mask=b_input_mask)\n",
    "    # get output\n",
    "    logits = outputs[0]\n",
    "    # move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    final_prediction = np.argmax(logits, axis=-1).flatten()\n",
    "    predictions.append(final_prediction)\n",
    "    true_labels.append(label_ids)\n",
    "    \n",
    "print('total time used is: {0:.2f} s'.format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bded3fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Claim dataset by the model trained on Manifesto dataset\n",
      "\n",
      "Precision on Unseen Test Set: 0.52\n",
      "Recall on Unseen Test Set: 0.77\n",
      "\n",
      "Accuracy on Unseen Test Set: 0.77\n",
      "F1-Score on Unseen Test Set: 0.78\n",
      "Balanced Accuracy on Unseen Test Set: 0.77\n",
      "\n",
      "Classification Report on Unseen Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.77      0.83      1982\n",
      "           1       0.52      0.77      0.62       665\n",
      "\n",
      "    accuracy                           0.77      2647\n",
      "   macro avg       0.72      0.77      0.73      2647\n",
      "weighted avg       0.81      0.77      0.78      2647\n",
      "\n",
      "Confusion Matrix on Unseen Test Set:\n",
      "[[1517  465]\n",
      " [ 155  510]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing Claim dataset by the model trained on Manifesto dataset\")\n",
    "print()\n",
    "from sklearn.metrics import f1_score\n",
    "# convert numeric label to string\n",
    "final_prediction_list = np.concatenate(predictions)\n",
    "\n",
    "# Evaluate precision\n",
    "precision = precision_score(climatebert_labels, final_prediction_list)\n",
    "# Evaluate recall\n",
    "recall = recall_score(climatebert_labels, final_prediction_list)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(climatebert_labels, final_prediction_list)\n",
    "\n",
    "# Evaluate F1-score\n",
    "f1_score = f1_score(climatebert_labels, final_prediction_list, average='weighted')\n",
    "\n",
    "# Evaluate balanced accuracy\n",
    "balanced_accuracy = balanced_accuracy_score(climatebert_labels, final_prediction_list)\n",
    "\n",
    "\n",
    "# Print evaluation metrics for Linear SVC on the unseen test set\n",
    "print(\"Precision on Unseen Test Set:\", round(precision,2))\n",
    "print(\"Recall on Unseen Test Set:\", round(recall,2))\n",
    "print()\n",
    "print(\"Accuracy on Unseen Test Set:\", round(accuracy,2))\n",
    "print(\"F1-Score on Unseen Test Set:\", round(f1_score,2))\n",
    "print(\"Balanced Accuracy on Unseen Test Set:\", round(balanced_accuracy,2))\n",
    "print()\n",
    "\n",
    "# Print classification report and confusion matrix for Linear SVC on the unseen test set\n",
    "print(\"Classification Report on Unseen Test Set:\")\n",
    "print(classification_report(climatebert_labels, final_prediction_list))\n",
    "print(\"Confusion Matrix on Unseen Test Set:\")\n",
    "print(confusion_matrix(climatebert_labels, final_prediction_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9518a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_for_error_analysis(text_list, true_labels, predicted_labels):\n",
    "    trained_dict = {}\n",
    "\n",
    "    for n, (text, true_label, predicted_label) in enumerate(zip(text_list, true_labels, predicted_labels), start=1):\n",
    "        trained_dict[str(n)] = {\n",
    "            \"sentence\": text,\n",
    "            \"true_label\": str(true_label),\n",
    "            \"predicted_label\": str(predicted_label)\n",
    "        }\n",
    "\n",
    "    final_list = [v for k, v in trained_dict.items()]\n",
    "    return final_list\n",
    "\n",
    "Tested_claims_trained_manifesto=dict_for_error_analysis(climatebert_text_original,climatebert_labels,final_prediction_list)\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d7593313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "output_file = open(\"Tested_claims_trained_manifesto.txt\", 'w', encoding='utf-8')\n",
    "for dic in Tested_claims_trained_manifesto:\n",
    "    json.dump(dic, output_file) \n",
    "    output_file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a932ed",
   "metadata": {},
   "source": [
    "# Inverse: train on Claim dataset and test on Manifesto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d2077fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# load tokens\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
    "# Use 80% for training and 20% for validation\n",
    "print(len(climatebert_text)==len(climatebert_labels))\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_inputs, validation_inputs, train_labels, validation_labels, train_masks, validation_masks = train_test_split(climatebert_tokenized_feature['input_ids'], \n",
    "                                                                                                             climatebert_labels,\n",
    "                                                                                                                    climatebert_tokenized_feature['attention_mask'],\n",
    "                                                                                                      random_state=42, test_size=0.2, stratify=climatebert_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cef8fe95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load base package for the tasks from pytorch\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "# define batch_size\n",
    "batch_size = 16\n",
    "# Create the DataLoader for our training set\n",
    "train_data = TensorDataset(train_inputs, train_masks, torch.tensor(train_labels))\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "# Create the DataLoader for our test set\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, torch.tensor(validation_labels))\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0427534e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# BertForSequenceClassification\n",
    "from transformers import XLMRobertaForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained(\n",
    "    \"xlm-roberta-base\", \n",
    "    # Specify number of classes\n",
    "    num_labels = len(set(climatebert_labels)), \n",
    "    # Whether the model returns attentions weights\n",
    "    output_attentions = False,\n",
    "    # Whether the model returns all hidden-states \n",
    "    output_hidden_states = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3529eb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 250002. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
      "/home/users/yabdul/.local/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XLMRobertaForSequenceClassification(\n",
       "  (roberta): XLMRobertaModel(\n",
       "    (embeddings): XLMRobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): XLMRobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): XLMRobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Receive the full size of the new word\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "# Optimizer & Learning Rate Scheduler\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, \n",
    "                  eps = 1e-8 \n",
    "                )\n",
    "\n",
    "# Number of training epochs\n",
    "epochs = 3\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "# Create the learning rate scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)\n",
    "\n",
    "# tell pytorch to run this model on GPU\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f670be41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 3 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.46\n",
      "  Training epcoh took: 0:00:23\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.78\n",
      "\n",
      "======== Epoch 2 / 3 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.29\n",
      "  Training epcoh took: 0:00:23\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.89\n",
      "\n",
      "======== Epoch 3 / 3 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.22\n",
      "  Training epcoh took: 0:00:23\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.91\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:01:35 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    # Perform one full pass over the training set.\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the device using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)        \n",
    "        loss = output.loss\n",
    "        total_train_loss += loss.item()\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    t0 = time.time()\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    best_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "            output= model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "        loss = output.loss\n",
    "        total_eval_loss += loss.item()\n",
    "        # Move logits and labels to CPU if we are using GPU\n",
    "        logits = output.logits\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    if avg_val_accuracy > best_eval_accuracy:\n",
    "        torch.save(model, 'inverse_climatebert_trained')\n",
    "        best_eval_accuracy = avg_val_accuracy\n",
    "    #print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    #print(\"  Validation took: {:}\".format(validation_time))\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "099dd5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('inverse_climatebert_trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00d5b66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(dataframe):\n",
    "    \n",
    "    sentences_cleaned = [clean_text(s) for s in dataframe[\"sentence\"]]\n",
    "    labels_numbers = [1 if s == 'Environmental Protection' else 0 for s in dataframe[\"detailed_label\"]]\n",
    "    return sentences_cleaned, labels_numbers\n",
    "\n",
    "\n",
    "dataframe =test_manifesto_dataframe.copy()\n",
    "manifesto_original_sentences= [s for s in dataframe[\"sentence\"]]\n",
    "manifesto_sentences_cleaned,manifesto_labels=preprocess_data(dataframe)\n",
    "print(len(manifesto_sentences_cleaned)==len(manifesto_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a61a9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize features \n",
    "MAX_LEN = 135\n",
    "manifesto_tokenized_feature = tokenizer.batch_encode_plus(\n",
    "                            # Sentences to encode\n",
    "                            manifesto_sentences_cleaned, \n",
    "                            # Add '[CLS]' and '[SEP]'\n",
    "                            add_special_tokens = True,\n",
    "                            # Add empty tokens if len(text)<MAX_LEN\n",
    "                            padding = 'max_length',\n",
    "                            # Truncate all sentences to max length\n",
    "                            truncation=True,\n",
    "                            # Set the maximum length\n",
    "                            max_length = MAX_LEN, \n",
    "                            # Return attention mask\n",
    "                            return_attention_mask = True,\n",
    "                            # Return pytorch tensors\n",
    "                            return_tensors = 'pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b0e647d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=16\n",
    "# Create the DataLoader for the climatebert dataset\n",
    "manifesto_validation_data = TensorDataset(manifesto_tokenized_feature['input_ids'], manifesto_tokenized_feature['attention_mask'], torch.tensor(manifesto_labels))\n",
    "validation_sampler = SequentialSampler(manifesto_validation_data)\n",
    "manifesto_validation_dataloader = DataLoader(manifesto_validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7eba3c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time used is: 421.07 s\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "import numpy as np\n",
    "t0 = time.time()\n",
    "# model in validation mode\n",
    "model.eval()\n",
    "# save prediction\n",
    "predictions,true_labels =[],[]\n",
    "# evaluate data for one epoch\n",
    "for batch in manifesto_validation_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    # validation\n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids,\n",
    "                        token_type_ids=None,\n",
    "                        attention_mask=b_input_mask)\n",
    "    # get output\n",
    "    logits = outputs[0]\n",
    "    # move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    final_prediction = np.argmax(logits, axis=-1).flatten()\n",
    "    predictions.append(final_prediction)\n",
    "    true_labels.append(label_ids)\n",
    "    \n",
    "print('total time used is: {0:.2f} s'.format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "befb1ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Manifesto dataset by the model trained on Claims dataset\n",
      "\n",
      "Precision on Unseen Test Set: 0.49\n",
      "Recall on Unseen Test Set: 0.39\n",
      "\n",
      "Accuracy on Unseen Test Set: 0.91\n",
      "F1-Score on Unseen Test Set: 0.91\n",
      "Balanced Accuracy on Unseen Test Set: 0.67\n",
      "\n",
      "Classification Report on Unseen Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95     77385\n",
      "           1       0.49      0.39      0.43      7475\n",
      "\n",
      "    accuracy                           0.91     84860\n",
      "   macro avg       0.71      0.67      0.69     84860\n",
      "weighted avg       0.90      0.91      0.91     84860\n",
      "\n",
      "Confusion Matrix on Unseen Test Set:\n",
      "[[74335  3050]\n",
      " [ 4597  2878]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing Manifesto dataset by the model trained on Claims dataset\")\n",
    "print()\n",
    "from sklearn.metrics import f1_score\n",
    "# convert numeric label to string\n",
    "final_prediction_list = np.concatenate(predictions)\n",
    "\n",
    "# Evaluate precision\n",
    "precision = precision_score(manifesto_labels, final_prediction_list)\n",
    "# Evaluate recall\n",
    "recall = recall_score(manifesto_labels, final_prediction_list)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(manifesto_labels, final_prediction_list)\n",
    "\n",
    "# Evaluate F1-score\n",
    "f1_score = f1_score(manifesto_labels, final_prediction_list, average='weighted')\n",
    "\n",
    "# Evaluate balanced accuracy\n",
    "balanced_accuracy = balanced_accuracy_score(manifesto_labels, final_prediction_list)\n",
    "\n",
    "# Print evaluation metrics for Linear SVC on the unseen test set\n",
    "print(\"Precision on Unseen Test Set:\", round(precision,2))\n",
    "print(\"Recall on Unseen Test Set:\", round(recall,2))\n",
    "print()\n",
    "print(\"Accuracy on Unseen Test Set:\", round(accuracy,2))\n",
    "print(\"F1-Score on Unseen Test Set:\", round(f1_score,2))\n",
    "print(\"Balanced Accuracy on Unseen Test Set:\", round(balanced_accuracy,2))\n",
    "print()\n",
    "\n",
    "# Print classification report and confusion matrix for Linear SVC on the unseen test set\n",
    "print(\"Classification Report on Unseen Test Set:\")\n",
    "print(classification_report(manifesto_labels, final_prediction_list))\n",
    "print(\"Confusion Matrix on Unseen Test Set:\")\n",
    "print(confusion_matrix(manifesto_labels, final_prediction_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15e3bcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_manifesto_train_Claims=dict_for_error_analysis(manifesto_original_sentences,manifesto_labels,final_prediction_list)\n",
    "output_file = open(\"Test_manifesto_train_Claims_right.txt\", 'w', encoding='utf-8')\n",
    "for dic in Test_manifesto_train_Claims:\n",
    "    json.dump(dic, output_file) \n",
    "    output_file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a294e2ff",
   "metadata": {},
   "source": [
    "# Transferability test: 10Ks dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a20d09f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test_10ks = pd.read_csv (\"10-Ks (2018, test).tsv\", sep = '\\t')\n",
    "train_10ks= pd.read_csv (\"AL-10Ks.tsv _ 3000 (58 positives, 2942 negatives) (TSV, 127138 KB).tsv\", sep = '\\t')\n",
    "train_10ks[\"sentence_cleaned\"] = train_10ks[\"sentence\"].apply(lambda x: clean_text(x))\n",
    "train_text_cleaned=list(train_10ks[\"sentence_cleaned\"])\n",
    "train_labels=list(train_10ks[\"label\"])\n",
    "test_10ks[\"sentence_cleaned\"] = test_10ks[\"sentence\"].apply(lambda x: clean_text(x))\n",
    "test_text_cleaned=list(test_10ks[\"sentence_cleaned\"])\n",
    "test_labels=list(test_10ks[\"label\"])\n",
    "train_text_cleaned.extend(test_text_cleaned)\n",
    "train_labels.extend(test_labels)\n",
    "\n",
    "original_text_10ks=list(train_10ks[\"sentence\"])\n",
    "original_text_10ks.extend(list(test_10ks[\"sentence\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a379aca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  127\n",
      "min:  3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([   0.,  200.,  400.,  600.,  800., 1000., 1200., 1400.]),\n",
       " [Text(0, 0.0, '0'),\n",
       "  Text(0, 200.0, '200'),\n",
       "  Text(0, 400.0, '400'),\n",
       "  Text(0, 600.0, '600'),\n",
       "  Text(0, 800.0, '800'),\n",
       "  Text(0, 1000.0, '1000'),\n",
       "  Text(0, 1200.0, '1200'),\n",
       "  Text(0, 1400.0, '1400')])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenize the text feature \n",
    "Ks10_tokenized_feature = tokenizer.batch_encode_plus(\n",
    "                            # Sentences to encode\n",
    "                            train_text_cleaned, \n",
    "                            # Add '[CLS]' and '[SEP]'\n",
    "                            add_special_tokens = True      \n",
    "                   )\n",
    "# collect tokenized sentence length \n",
    "token_sentence_length = [len(x) for x in Ks10_tokenized_feature['input_ids']]\n",
    "print('max: ', max(token_sentence_length))\n",
    "print('min: ', min(token_sentence_length))\n",
    "MAX_LEN = max(token_sentence_length)\n",
    "# plot the distribution\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.hist(token_sentence_length, rwidth = 0.9)\n",
    "plt.xlabel('Sequence Length', fontsize = 18)\n",
    "plt.ylabel('Number of Samples', fontsize = 18)\n",
    "plt.xticks(fontsize = 14)\n",
    "plt.yticks(fontsize = 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8130a368",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ks10_tokenized_feature = tokenizer.batch_encode_plus(\n",
    "                            # Sentences to encode\n",
    "                            train_text_cleaned, \n",
    "                            # Add '[CLS]' and '[SEP]'\n",
    "                            add_special_tokens = True,\n",
    "                            # Add empty tokens if len(text)<MAX_LEN\n",
    "                            padding = 'max_length',\n",
    "                            # Truncate all sentences to max length\n",
    "                            truncation=True,\n",
    "                            # Set the maximum length\n",
    "                            max_length = MAX_LEN, \n",
    "                            # Return attention mask\n",
    "                            return_attention_mask = True,\n",
    "                            # Return pytorch tensors\n",
    "                            return_tensors = 'pt'    )\n",
    "\n",
    "\n",
    "batch_size=16\n",
    "# Create the DataLoader for the climatebert dataset\n",
    "Ks10_validation_data = TensorDataset(Ks10_tokenized_feature['input_ids'],Ks10_tokenized_feature['attention_mask'], torch.tensor(train_labels))\n",
    "validation_sampler = SequentialSampler(Ks10_validation_data)\n",
    "Ks10_validation_dataloader = DataLoader(Ks10_validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5b9cbb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD the model\n",
    "model = torch.load('Roberta_10percent_OneStep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "76574251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time used is: 13.11 s\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "import numpy as np\n",
    "t0 = time.time()\n",
    "# model in validation mode\n",
    "model.eval()\n",
    "# save prediction\n",
    "predictions,true_labels =[],[]\n",
    "# evaluate data for one epoch\n",
    "for batch in Ks10_validation_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    # validation\n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids,\n",
    "                        token_type_ids=None,\n",
    "                        attention_mask=b_input_mask)\n",
    "    # get output\n",
    "    logits = outputs[0]\n",
    "    # move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    final_prediction = np.argmax(logits, axis=-1).flatten()\n",
    "    predictions.append(final_prediction)\n",
    "    true_labels.append(label_ids)\n",
    "    \n",
    "print('total time used is: {0:.2f} s'.format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7f45475b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on 10-K files dataset\n",
      "\n",
      "Precision on Unseen Test Set: 0.3\n",
      "Recall on Unseen Test Set: 0.74\n",
      "\n",
      "Accuracy on Unseen Test Set: 0.93\n",
      "F1-Score on Unseen Test Set: 0.94\n",
      "Balanced Accuracy on Unseen Test Set: 0.84\n",
      "\n",
      "Classification Report on Unseen Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.93      0.96      3175\n",
      "           1       0.30      0.74      0.43       125\n",
      "\n",
      "    accuracy                           0.93      3300\n",
      "   macro avg       0.65      0.84      0.70      3300\n",
      "weighted avg       0.96      0.93      0.94      3300\n",
      "\n",
      "Confusion Matrix on Unseen Test Set:\n",
      "[[2963  212]\n",
      " [  32   93]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Test on 10-K files dataset\")\n",
    "print()\n",
    "from sklearn.metrics import f1_score\n",
    "final_prediction_list =list(np.concatenate(predictions)) \n",
    "# Evaluate precision\n",
    "precision = precision_score(train_labels, final_prediction_list)\n",
    "# Evaluate recall\n",
    "recall = recall_score(train_labels, final_prediction_list)\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(train_labels, final_prediction_list)\n",
    "\n",
    "# Evaluate F1-score\n",
    "f1_score = f1_score(train_labels, final_prediction_list, average='weighted')\n",
    "\n",
    "# Evaluate balanced accuracy\n",
    "balanced_accuracy = balanced_accuracy_score(train_labels, final_prediction_list)\n",
    "\n",
    "# Print evaluation metrics for Linear SVC on the unseen test set\n",
    "print(\"Precision on Unseen Test Set:\", round(precision,2))\n",
    "print(\"Recall on Unseen Test Set:\", round(recall,2))\n",
    "print()\n",
    "print(\"Accuracy on Unseen Test Set:\", round(accuracy,2))\n",
    "print(\"F1-Score on Unseen Test Set:\", round(f1_score,2))\n",
    "print(\"Balanced Accuracy on Unseen Test Set:\", round(balanced_accuracy,2))\n",
    "print()\n",
    "\n",
    "# Print classification report and confusion matrix for Linear SVC on the unseen test set\n",
    "print(\"Classification Report on Unseen Test Set:\")\n",
    "print(classification_report(train_labels, final_prediction_list))\n",
    "print(\"Confusion Matrix on Unseen Test Set:\")\n",
    "print(confusion_matrix(train_labels, final_prediction_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d509dfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_10ks_train_mainfesto=dict_for_error_analysis(original_text_10ks,train_labels,final_prediction_list)\n",
    "output_file = open(\"Test_10ks_train_mainfesto.txt\", 'w', encoding='utf-8')\n",
    "for dic in Test_10ks_train_mainfesto:\n",
    "    json.dump(dic, output_file) \n",
    "    output_file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92665ab8",
   "metadata": {},
   "source": [
    "# Inverse: trained on 10KS, tested on Manifesto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "10a66d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokens\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
    "# Use 80% for training and 20% for validation\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_inputs, validation_inputs, train_labels, validation_labels, train_masks, validation_masks = train_test_split(Ks10_tokenized_feature['input_ids'], \n",
    "                                                                                                             train_labels,\n",
    "                                                                                                                    Ks10_tokenized_feature['attention_mask'],\n",
    "                                                                                                      random_state=42, test_size=0.2, stratify=train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c0d101aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# load base package for the tasks from pytorch\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "# define batch_size\n",
    "batch_size = 16\n",
    "# Create the DataLoader for our training set\n",
    "train_data = TensorDataset(train_inputs, train_masks, torch.tensor(train_labels))\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "# Create the DataLoader for our test set\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, torch.tensor(validation_labels))\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "\n",
    "# BertForSequenceClassification\n",
    "from transformers import XLMRobertaForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained(\n",
    "    \"xlm-roberta-base\", \n",
    "    # Specify number of classes\n",
    "    num_labels = len(set(train_labels)), \n",
    "    # Whether the model returns attentions weights\n",
    "    output_attentions = False,\n",
    "    # Whether the model returns all hidden-states \n",
    "    output_hidden_states = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "01db03fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 250002. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n",
      "/home/users/yabdul/.local/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XLMRobertaForSequenceClassification(\n",
       "  (roberta): XLMRobertaModel(\n",
       "    (embeddings): XLMRobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): XLMRobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): XLMRobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Receive the full size of the new word\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "# Optimizer & Learning Rate Scheduler\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, \n",
    "                  eps = 1e-8 \n",
    "                )\n",
    "\n",
    "# Number of training epochs\n",
    "epochs = 3\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "# Create the learning rate scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)\n",
    "\n",
    "# tell pytorch to run this model on GPU\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d9926fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 3 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.20\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "\n",
      "======== Epoch 2 / 3 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.16\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "\n",
      "======== Epoch 3 / 3 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.14\n",
      "  Training epcoh took: 0:00:40\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.96\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:04:07 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    # Perform one full pass over the training set.\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the device using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)        \n",
    "        loss = output.loss\n",
    "        total_train_loss += loss.item()\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    t0 = time.time()\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    best_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "            output= model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "        loss = output.loss\n",
    "        total_eval_loss += loss.item()\n",
    "        # Move logits and labels to CPU if we are using GPU\n",
    "        logits = output.logits\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    if avg_val_accuracy > best_eval_accuracy:\n",
    "        torch.save(model, 'inverse_10ks_trained')\n",
    "        best_eval_accuracy = avg_val_accuracy\n",
    "    #print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    #print(\"  Validation took: {:}\".format(validation_time))\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7abfd783",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('inverse_10ks_trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d47a1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize features \n",
    "MAX_LEN = 135\n",
    "manifesto_tokenized_feature = tokenizer.batch_encode_plus(\n",
    "                            # Sentences to encode\n",
    "                            manifesto_sentences_cleaned, \n",
    "                            # Add '[CLS]' and '[SEP]'\n",
    "                            add_special_tokens = True,\n",
    "                            # Add empty tokens if len(text)<MAX_LEN\n",
    "                            padding = 'max_length',\n",
    "                            # Truncate all sentences to max length\n",
    "                            truncation=True,\n",
    "                            # Set the maximum length\n",
    "                            max_length = MAX_LEN, \n",
    "                            # Return attention mask\n",
    "                            return_attention_mask = True,\n",
    "                            # Return pytorch tensors\n",
    "                            return_tensors = 'pt')\n",
    "\n",
    "batch_size=16\n",
    "# Create the DataLoader for the climatebert dataset\n",
    "manifesto_validation_data = TensorDataset(manifesto_tokenized_feature['input_ids'], manifesto_tokenized_feature['attention_mask'], torch.tensor(manifesto_labels))\n",
    "validation_sampler = SequentialSampler(manifesto_validation_data)\n",
    "manifesto_validation_dataloader = DataLoader(manifesto_validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "414418de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time used is: 419.96 s\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "import numpy as np\n",
    "t0 = time.time()\n",
    "# model in validation mode\n",
    "model.eval()\n",
    "# save prediction\n",
    "predictions,true_labels =[],[]\n",
    "# evaluate data for one epoch\n",
    "for batch in manifesto_validation_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    # validation\n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids,\n",
    "                        token_type_ids=None,\n",
    "                        attention_mask=b_input_mask)\n",
    "    # get output\n",
    "    logits = outputs[0]\n",
    "    # move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    final_prediction = np.argmax(logits, axis=-1).flatten()\n",
    "    predictions.append(final_prediction)\n",
    "    true_labels.append(label_ids)\n",
    "    \n",
    "print('total time used is: {0:.2f} s'.format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5b2dfc17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on Manifesto dataset by the model trained on 10KS dataset\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision on Unseen Test Set: 0.83\n",
      "Recall on Unseen Test Set: 0.91\n",
      "\n",
      "Accuracy on Unseen Test Set: 0.91\n",
      "F1-Score on Unseen Test Set: 0.87\n",
      "Balanced Accuracy on Unseen Test Set: 0.5\n",
      "\n",
      "Classification Report on Unseen Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     77385\n",
      "           1       0.00      0.00      0.00      7475\n",
      "\n",
      "    accuracy                           0.91     84860\n",
      "   macro avg       0.46      0.50      0.48     84860\n",
      "weighted avg       0.83      0.91      0.87     84860\n",
      "\n",
      "Confusion Matrix on Unseen Test Set:\n",
      "[[77385     0]\n",
      " [ 7475     0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing on Manifesto dataset by the model trained on 10KS dataset\")\n",
    "print()\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# convert numeric label to string\n",
    "final_prediction_list = np.concatenate(predictions)\n",
    "# Evaluate precision\n",
    "precision = precision_score(manifesto_labels, final_prediction_list, average='weighted')\n",
    "# Evaluate recall\n",
    "recall = recall_score(manifesto_labels, final_prediction_list, average='weighted')\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(manifesto_labels, final_prediction_list)\n",
    "\n",
    "# Evaluate F1-score\n",
    "f1_score = f1_score(manifesto_labels, final_prediction_list, average='weighted')\n",
    "\n",
    "# Evaluate balanced accuracy\n",
    "balanced_accuracy = balanced_accuracy_score(manifesto_labels, final_prediction_list)\n",
    "\n",
    "# Print evaluation metrics for Linear SVC on the unseen test set\n",
    "print(\"Precision on Unseen Test Set:\", round(precision,2))\n",
    "print(\"Recall on Unseen Test Set:\", round(recall,2))\n",
    "print()\n",
    "print(\"Accuracy on Unseen Test Set:\", round(accuracy,2))\n",
    "print(\"F1-Score on Unseen Test Set:\", round(f1_score,2))\n",
    "print(\"Balanced Accuracy on Unseen Test Set:\", round(balanced_accuracy,2))\n",
    "print()\n",
    "\n",
    "# Print classification report and confusion matrix for Linear SVC on the unseen test set\n",
    "print(\"Classification Report on Unseen Test Set:\")\n",
    "print(classification_report(manifesto_labels, final_prediction_list))\n",
    "print(\"Confusion Matrix on Unseen Test Set:\")\n",
    "print(confusion_matrix(manifesto_labels, final_prediction_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9d95589",
   "metadata": {},
   "outputs": [],
   "source": [
    "Test_manifesto_train_10ks=dict_for_error_analysis(manifesto_original_sentences,manifesto_labels,final_prediction_list)\n",
    "output_file = open(\"Test_manifesto_train_10ks_right.txt\", 'w', encoding='utf-8')\n",
    "for dic in Test_manifesto_train_10ks:\n",
    "    json.dump(dic, output_file) \n",
    "    output_file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b441322b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80cd81b1",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79f916d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11170]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "import subprocess as sp\n",
    "import os\n",
    "def get_gpu_memory():\n",
    "    command = \"nvidia-smi --query-gpu=memory.free --format=csv\"\n",
    "    memory_free_info = sp.check_output(command.split()).decode('ascii').split('\\n')[:-1][1:]\n",
    "    memory_free_values = [int(x.split()[0]) for i, x in enumerate(memory_free_info)]\n",
    "    return memory_free_values\n",
    "\n",
    "get_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c20c53b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import json\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "with open('test_dataset.json', 'r') as fp:\n",
    "    test_dataset = json.load(fp)\n",
    "with open('train_dataset.json', 'r') as fp:\n",
    "    train_dataset = json.load(fp)\n",
    "f = open('/data/data_codebook.json')\n",
    "data_codebook = json.load(f)\n",
    "super_set={}\n",
    "for s in data_codebook:\n",
    "    if s[2]!=\"domain_name\":\n",
    "        if s[2] not in super_set:\n",
    "            super_set[s[2]]=[]\n",
    "        if s[5] not in super_set[s[2]]:\n",
    "            super_set[s[2]].append(s[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1536de84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
    "sw = stopwords.words('english')\n",
    "\n",
    "def clean_text(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", text) # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "\n",
    "    text = re.sub(r\"http\\S+\", \"\",text) #Removing URLs \n",
    "    #text = re.sub(r\"http\", \"\",text)\n",
    "    \n",
    "    html=re.compile(r'<.*?>') \n",
    "    \n",
    "    text = html.sub(r'',text) #Removing html tags\n",
    "    \n",
    "    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\" + '_'\n",
    "    for p in punctuations:\n",
    "        text = text.replace(p,'') #Removing punctuations\n",
    "        \n",
    "    text = [word.lower() for word in text.split() if word.lower() not in sw]\n",
    "    \n",
    "    text = \" \".join(text) #removing stopwords\n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text) #Removing emojis\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac8ed99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dataset_counts(dataset):\n",
    "    count_dataset = {\n",
    "        \"general\": {},\n",
    "        \"detailed\": {}\n",
    "    }\n",
    "    \n",
    "    for s in dataset:\n",
    "        detailed_label = s['detailed_label']\n",
    "        general_label = s[\"general_label\"]\n",
    "        \n",
    "        if detailed_label not in count_dataset[\"detailed\"]:\n",
    "            count_dataset[\"detailed\"][detailed_label] = 0\n",
    "        count_dataset[\"detailed\"][detailed_label] += 1\n",
    "\n",
    "        if general_label not in count_dataset[\"general\"]:\n",
    "            count_dataset[\"general\"][general_label] = 0\n",
    "        count_dataset[\"general\"][general_label] += 1\n",
    "    \n",
    "    return count_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "939487ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_welfare_categories(dataset):\n",
    "    welfare_categories = {}\n",
    "    for key, value in super_set.items():\n",
    "        if key != 'Welfare and Quality of Life':\n",
    "            continue\n",
    "        for category in value:\n",
    "            welfare_categories[category] =dataset[category]\n",
    "    \n",
    "    return welfare_categories\n",
    "\n",
    "welfare_categories_train=extract_welfare_categories(train_dataset)\n",
    "welfare_categories_test=extract_welfare_categories(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dccf4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_custom_dataset(balanced_dataset, total_limit, desired_percentage):\n",
    "    used_sentences = set()\n",
    "    dataset = []\n",
    "    welfare_count = 0\n",
    "    welfare_limit = int(total_limit * desired_percentage)\n",
    "    category_limits = {category: 100 for category in balanced_dataset.keys()}\n",
    "\n",
    "    # Calculate the total number of sentences in the dataset\n",
    "    total_sentences = sum(len(v) for v in balanced_dataset.values())\n",
    "\n",
    "    # First, add sentences from 'Environmental Protection'\n",
    "    for sentence in balanced_dataset['Environmental Protection']:\n",
    "        if len(dataset) >= welfare_limit:\n",
    "            break\n",
    "\n",
    "        if sentence not in used_sentences:\n",
    "            per_line_dict = {\n",
    "                \"sentence\": sentence,\n",
    "                \"detailed_label\": 'Environmental Protection',\n",
    "                \"general_label\": 'Welfare and Quality of Life'\n",
    "            }\n",
    "            dataset.append(per_line_dict)\n",
    "            used_sentences.add(sentence)\n",
    "            welfare_count += 1\n",
    "\n",
    "    # Then, add sentences from other categories\n",
    "    while len(dataset) < total_limit:\n",
    "        for category, sentences in balanced_dataset.items():\n",
    "            if len(dataset) >= total_limit:\n",
    "                break\n",
    "            if category != 'Environmental Protection':\n",
    "                for key, value in super_set.items():\n",
    "                    if category in value:\n",
    "                        super_label = key\n",
    "\n",
    "                category_limit = min(len(sentences), category_limits[category])\n",
    "\n",
    "                limit = min(100, category_limit)\n",
    "\n",
    "                for sentence in sentences:\n",
    "                    if limit == 0 or len(dataset) >= total_limit:\n",
    "                        break\n",
    "\n",
    "                    if sentence not in used_sentences:\n",
    "                        per_line_dict = {\n",
    "                            \"sentence\": sentence,\n",
    "                            \"detailed_label\": category,\n",
    "                            \"general_label\": super_label\n",
    "                        }\n",
    "                        dataset.append(per_line_dict)\n",
    "                        used_sentences.add(sentence)\n",
    "                        limit -= 1\n",
    "                        category_limits[category] += 100\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d91ecea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences in the dataset: 56000\n",
      "{'Welfare and Quality of Life': 56000}\n",
      "56000\n",
      "11\n",
      "{'Environmental Protection': 16800, 'Culture: Positive': 8300, 'Equality: Positive': 8294, 'Welfare State Expansion': 8200, 'Welfare State Limitation': 5380, 'Education Expansion': 8200, 'Education Limitation': 515, 'Private-Public Mix in Culture: Positive': 36, 'Private-Public Mix in Social Justice: Positive': 1, 'Private-Public Mix in Welfare: Positive': 227, 'Private-Public Mix in Education: Positive': 47}\n"
     ]
    }
   ],
   "source": [
    "\"Experiment 1\"\n",
    "total_limit = 56000\n",
    "desired_percentage = 0.3\n",
    "\n",
    "dataset = create_custom_dataset(welfare_categories_train, total_limit, desired_percentage)\n",
    "\n",
    "print(\"Total sentences in the dataset:\", len(dataset))\n",
    "\n",
    "# Usage example:\n",
    "# Assuming you have the 'dataset' variable containing the dataset obtained from the create_custom_dataset function\n",
    "# Replace this with the actual dataset you want to count.\n",
    "count_dataset = calculate_dataset_counts(dataset)\n",
    "print(count_dataset[\"general\"])\n",
    "print(sum(count_dataset[\"general\"].values()))\n",
    "print(len(count_dataset[\"detailed\"].keys()))\n",
    "print(count_dataset[\"detailed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebe0125",
   "metadata": {},
   "source": [
    "# RoBerta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49afe225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokens\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "226eee6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>detailed_label</th>\n",
       "      <th>general_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35681</th>\n",
       "      <td>That all municipalities offer cultural cards ...</td>\n",
       "      <td>Culture: Positive</td>\n",
       "      <td>Welfare and Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12027</th>\n",
       "      <td>The erosion of Swiss biodiversity continues, ...</td>\n",
       "      <td>Environmental Protection</td>\n",
       "      <td>Welfare and Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2704</th>\n",
       "      <td>For environmentalists, the main provisions are:</td>\n",
       "      <td>Environmental Protection</td>\n",
       "      <td>Welfare and Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25200</th>\n",
       "      <td>DPA in the field of art galleries includes th...</td>\n",
       "      <td>Culture: Positive</td>\n",
       "      <td>Welfare and Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7441</th>\n",
       "      <td>In this direction of guaranteeing animal welf...</td>\n",
       "      <td>Environmental Protection</td>\n",
       "      <td>Welfare and Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13182</th>\n",
       "      <td>A \"Program of measures to achieve the environ...</td>\n",
       "      <td>Environmental Protection</td>\n",
       "      <td>Welfare and Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38431</th>\n",
       "      <td>as well as reinforcing Home Palliative Care, ...</td>\n",
       "      <td>Welfare State Limitation</td>\n",
       "      <td>Welfare and Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44363</th>\n",
       "      <td>Taking away the ability to work opens up a hu...</td>\n",
       "      <td>Welfare State Expansion</td>\n",
       "      <td>Welfare and Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26964</th>\n",
       "      <td>First of all: what does 'socialisation of car...</td>\n",
       "      <td>Welfare State Limitation</td>\n",
       "      <td>Welfare and Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15497</th>\n",
       "      <td>Anywhere we see or hear about animal abuse, w...</td>\n",
       "      <td>Environmental Protection</td>\n",
       "      <td>Welfare and Quality of Life</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  \\\n",
       "35681   That all municipalities offer cultural cards ...   \n",
       "12027   The erosion of Swiss biodiversity continues, ...   \n",
       "2704     For environmentalists, the main provisions are:   \n",
       "25200   DPA in the field of art galleries includes th...   \n",
       "7441    In this direction of guaranteeing animal welf...   \n",
       "...                                                  ...   \n",
       "13182   A \"Program of measures to achieve the environ...   \n",
       "38431   as well as reinforcing Home Palliative Care, ...   \n",
       "44363   Taking away the ability to work opens up a hu...   \n",
       "26964   First of all: what does 'socialisation of car...   \n",
       "15497   Anywhere we see or hear about animal abuse, w...   \n",
       "\n",
       "                 detailed_label                general_label  \n",
       "35681         Culture: Positive  Welfare and Quality of Life  \n",
       "12027  Environmental Protection  Welfare and Quality of Life  \n",
       "2704   Environmental Protection  Welfare and Quality of Life  \n",
       "25200         Culture: Positive  Welfare and Quality of Life  \n",
       "7441   Environmental Protection  Welfare and Quality of Life  \n",
       "...                         ...                          ...  \n",
       "13182  Environmental Protection  Welfare and Quality of Life  \n",
       "38431  Welfare State Limitation  Welfare and Quality of Life  \n",
       "44363   Welfare State Expansion  Welfare and Quality of Life  \n",
       "26964  Welfare State Limitation  Welfare and Quality of Life  \n",
       "15497  Environmental Protection  Welfare and Quality of Life  \n",
       "\n",
       "[56000 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.DataFrame(data=(dataset))\n",
    "dataframe=shuffle(dataframe).dropna()\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b6ec85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences=list(dataframe[\"sentence\"])\n",
    "train_labels=[]\n",
    "for s in list(dataframe[\"detailed_label\"]):\n",
    "    if s=='Environmental Protection':\n",
    "        number=1\n",
    "    else:\n",
    "        number=0\n",
    "    train_labels.append(number)\n",
    "\n",
    "train_sentences_cleaned=[]\n",
    "for s in list(dataframe[\"sentence\"]):\n",
    "    cleaned=clean_text(s)\n",
    "    train_sentences_cleaned.append(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62bdc231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  135\n",
      "min:  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'The distribution of sequence length, when the percentage of Welfare sentences is: 30.0%')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenize the text feature \n",
    "tokenized_feature_raw = tokenizer.batch_encode_plus(\n",
    "                            # Sentences to encode\n",
    "                            train_sentences_cleaned, \n",
    "                            # Add '[CLS]' and '[SEP]'\n",
    "                            add_special_tokens = True      \n",
    "                   )\n",
    "# collect tokenized sentence length \n",
    "token_sentence_length = [len(x) for x in tokenized_feature_raw['input_ids']]\n",
    "print('max: ', max(token_sentence_length))\n",
    "print('min: ', min(token_sentence_length))\n",
    "# plot the distribution\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.hist(token_sentence_length, rwidth = 0.9)\n",
    "plt.xlabel('Sequence Length', fontsize = 18)\n",
    "plt.ylabel('Number of Samples', fontsize = 18)\n",
    "plt.xticks(fontsize = 14)\n",
    "plt.yticks(fontsize = 14)\n",
    "plt.title(\"The distribution of sequence length, when the percentage of Welfare sentences is: \"+str(desired_percentage*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49e63e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize features \n",
    "MAX_LEN = 135\n",
    "tokenized_feature = tokenizer.batch_encode_plus(\n",
    "                            # Sentences to encode\n",
    "                            train_sentences_cleaned, \n",
    "                            # Add '[CLS]' and '[SEP]'\n",
    "                            add_special_tokens = True,\n",
    "                            # Add empty tokens if len(text)<MAX_LEN\n",
    "                            padding = 'max_length',\n",
    "                            # Truncate all sentences to max length\n",
    "                            truncation=True,\n",
    "                            # Set the maximum length\n",
    "                            max_length = MAX_LEN, \n",
    "                            # Return attention mask\n",
    "                            return_attention_mask = True,\n",
    "                            # Return pytorch tensors\n",
    "                            return_tensors = 'pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "361641ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 80% for training and 20% for validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_inputs, validation_inputs, train_labels, validation_labels, train_masks, validation_masks = train_test_split(tokenized_feature['input_ids'], \n",
    "                                                                                                             train_labels,\n",
    "                                                                                                                    tokenized_feature['attention_mask'],\n",
    "                                                                                                      random_state=42, test_size=0.2, stratify=train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "329cf7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load base package for the tasks from pytorch\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "# define batch_size\n",
    "batch_size = 16\n",
    "# Create the DataLoader for our training set\n",
    "train_data = TensorDataset(train_inputs, train_masks, torch.tensor(train_labels))\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "# Create the DataLoader for our test set\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, torch.tensor(validation_labels))\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3e573e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load base package for the tasks from pytorch\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d468d2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# BertForSequenceClassification\n",
    "from transformers import XLMRobertaForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained(\n",
    "    \"xlm-roberta-base\", \n",
    "    # Specify number of classes\n",
    "    num_labels = len(set(train_labels)), \n",
    "    # Whether the model returns attentions weights\n",
    "    output_attentions = False,\n",
    "    # Whether the model returns all hidden-states \n",
    "    output_hidden_states = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73091f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 250002. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(250002, 768, padding_idx=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Receive the full size of the new word\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a73d782",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/yabdul/.local/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Optimizer & Learning Rate Scheduler\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, \n",
    "                  eps = 1e-8 \n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a3043c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of training epochs\n",
    "epochs = 3\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "# Create the learning rate scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f366a34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaForSequenceClassification(\n",
       "  (roberta): XLMRobertaModel(\n",
       "    (embeddings): XLMRobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): XLMRobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): XLMRobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tell pytorch to run this model on GPU\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23de45ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ebc3e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "import time\n",
    "import datetime\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "torch.cuda.empty_cache()\n",
    "# start training from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c83f4751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 3 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.23\n",
      "  Training epcoh took: 0:12:44\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.94\n",
      "\n",
      "======== Epoch 2 / 3 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.17\n",
      "  Training epcoh took: 0:12:44\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.94\n",
      "\n",
      "======== Epoch 3 / 3 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.15\n",
      "  Training epcoh took: 0:12:44\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.94\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:41:33 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    # Perform one full pass over the training set.\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the device using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)        \n",
    "        loss = output.loss\n",
    "        total_train_loss += loss.item()\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    t0 = time.time()\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    best_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "            output= model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "        loss = output.loss\n",
    "        total_eval_loss += loss.item()\n",
    "        # Move logits and labels to CPU if we are using GPU\n",
    "        logits = output.logits\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    if avg_val_accuracy > best_eval_accuracy:\n",
    "        torch.save(model, 'Roberta_30percent_TwoStep_Detailed')\n",
    "        best_eval_accuracy = avg_val_accuracy\n",
    "    #print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    #print(\"  Validation took: {:}\".format(validation_time))\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "063c2b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('Roberta_30percent_TwoStep_Detailed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574c6b8b",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0bae313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Now test the model on another unseen test sets--------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>detailed_label</th>\n",
       "      <th>general_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24153</th>\n",
       "      <td>Instead of facing the austerity policies from ...</td>\n",
       "      <td>Welfare State Expansion</td>\n",
       "      <td>Welfare and Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16272</th>\n",
       "      <td>pensions in payment will continue to be finan...</td>\n",
       "      <td>Welfare State Expansion</td>\n",
       "      <td>Welfare and Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2625</th>\n",
       "      <td>We have ensured an environmental policy awake...</td>\n",
       "      <td>Environmental Protection</td>\n",
       "      <td>Welfare and Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18274</th>\n",
       "      <td>Regionalization should also be followed by th...</td>\n",
       "      <td>Welfare State Expansion</td>\n",
       "      <td>Welfare and Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>FOR AN ECO-SOCIALIST ALTERNATIVE</td>\n",
       "      <td>Environmental Protection</td>\n",
       "      <td>Welfare and Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18816</th>\n",
       "      <td>supervision over the execution of works is ca...</td>\n",
       "      <td>Welfare State Expansion</td>\n",
       "      <td>Welfare and Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19249</th>\n",
       "      <td>The Green Liberals are striving for autonomou...</td>\n",
       "      <td>Welfare State Expansion</td>\n",
       "      <td>Welfare and Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11375</th>\n",
       "      <td>Property needs appreciation!</td>\n",
       "      <td>Equality: Positive</td>\n",
       "      <td>Welfare and Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25785</th>\n",
       "      <td>replacing school dropout and general tuition ...</td>\n",
       "      <td>Education Expansion</td>\n",
       "      <td>Welfare and Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17900</th>\n",
       "      <td>Private and company pension schemes do not co...</td>\n",
       "      <td>Welfare State Expansion</td>\n",
       "      <td>Welfare and Quality of Life</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29389 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  \\\n",
       "24153  Instead of facing the austerity policies from ...   \n",
       "16272   pensions in payment will continue to be finan...   \n",
       "2625    We have ensured an environmental policy awake...   \n",
       "18274   Regionalization should also be followed by th...   \n",
       "760                     FOR AN ECO-SOCIALIST ALTERNATIVE   \n",
       "...                                                  ...   \n",
       "18816   supervision over the execution of works is ca...   \n",
       "19249   The Green Liberals are striving for autonomou...   \n",
       "11375                       Property needs appreciation!   \n",
       "25785   replacing school dropout and general tuition ...   \n",
       "17900   Private and company pension schemes do not co...   \n",
       "\n",
       "                 detailed_label                general_label  \n",
       "24153   Welfare State Expansion  Welfare and Quality of Life  \n",
       "16272   Welfare State Expansion  Welfare and Quality of Life  \n",
       "2625   Environmental Protection  Welfare and Quality of Life  \n",
       "18274   Welfare State Expansion  Welfare and Quality of Life  \n",
       "760    Environmental Protection  Welfare and Quality of Life  \n",
       "...                         ...                          ...  \n",
       "18816   Welfare State Expansion  Welfare and Quality of Life  \n",
       "19249   Welfare State Expansion  Welfare and Quality of Life  \n",
       "11375        Equality: Positive  Welfare and Quality of Life  \n",
       "25785       Education Expansion  Welfare and Quality of Life  \n",
       "17900   Welfare State Expansion  Welfare and Quality of Life  \n",
       "\n",
       "[29389 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"-----Now test the model on another unseen test sets--------\")\n",
    "test_dataframe=[]\n",
    "for k,v in welfare_categories_test.items():\n",
    "    for key, value in super_set.items():\n",
    "        if k in value:\n",
    "            super_label = key\n",
    "    for s in v:\n",
    "            per_line_dict = {}\n",
    "            per_line_dict[\"sentence\"] = s\n",
    "            per_line_dict[\"detailed_label\"] = k\n",
    "            per_line_dict[\"general_label\"] = super_label\n",
    "            test_dataframe.append(per_line_dict)\n",
    "\n",
    "test_dataframe = pd.DataFrame(data=(test_dataframe))\n",
    "test_dataframe=shuffle(test_dataframe).dropna()\n",
    "test_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6aea2740",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences_cleaned=[]\n",
    "for s in list(test_dataframe[\"sentence\"]):\n",
    "    cleaned=clean_text(s)\n",
    "    test_sentences_cleaned.append(cleaned)\n",
    "\n",
    "test_labels_numbers=[]\n",
    "for s in list(test_dataframe[\"detailed_label\"]):\n",
    "    if s=='Environmental Protection':\n",
    "        number=1\n",
    "    else:\n",
    "        number=0\n",
    "    test_labels_numbers.append(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c14491a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_sentences_cleaned)==len(test_labels_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ec1a2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  147\n",
      "min:  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Test set.The distribution of sequence length, when the percentage of Welfare sentences is: 30.0%')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenize the text feature \n",
    "test_tokenized_feature = tokenizer.batch_encode_plus(\n",
    "                            # Sentences to encode\n",
    "                            test_sentences_cleaned, \n",
    "                            # Add '[CLS]' and '[SEP]'\n",
    "                            add_special_tokens = True      \n",
    "                   )\n",
    "# collect tokenized sentence length \n",
    "token_sentence_length = [len(x) for x in test_tokenized_feature['input_ids']]\n",
    "print('max: ', max(token_sentence_length))\n",
    "print('min: ', min(token_sentence_length))\n",
    "# plot the distribution\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.hist(token_sentence_length, rwidth = 0.9)\n",
    "plt.xlabel('Sequence Length', fontsize = 18)\n",
    "plt.ylabel('Number of Samples', fontsize = 18)\n",
    "plt.xticks(fontsize = 14)\n",
    "plt.yticks(fontsize = 14)\n",
    "plt.title(\"Test set.The distribution of sequence length, when the percentage of Welfare sentences is: \"+str(desired_percentage*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0dea8a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize features \n",
    "MAX_LEN = 147\n",
    "test_tokenized_feature = tokenizer.batch_encode_plus(\n",
    "                            # Sentences to encode\n",
    "                            test_sentences_cleaned, \n",
    "                            # Add '[CLS]' and '[SEP]'\n",
    "                            add_special_tokens = True,\n",
    "                            # Add empty tokens if len(text)<MAX_LEN\n",
    "                            padding = 'max_length',\n",
    "                            # Truncate all sentences to max length\n",
    "                            truncation=True,\n",
    "                            # Set the maximum length\n",
    "                            max_length = MAX_LEN, \n",
    "                            # Return attention mask\n",
    "                            return_attention_mask = True,\n",
    "                            # Return pytorch tensors\n",
    "                            return_tensors = 'pt'     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "09c8d26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataLoader for our test set\n",
    "validation_data = TensorDataset(test_tokenized_feature['input_ids'], test_tokenized_feature['attention_mask'], torch.tensor(test_labels_numbers))\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "245af2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time used is: 134.61 s\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "import numpy as np\n",
    "t0 = time.time()\n",
    "# model in validation mode\n",
    "model.eval()\n",
    "# save prediction\n",
    "predictions,true_labels =[],[]\n",
    "# evaluate data for one epoch\n",
    "for batch in validation_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    # validation\n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids,\n",
    "                        token_type_ids=None,\n",
    "                        attention_mask=b_input_mask)\n",
    "    # get output\n",
    "    logits = outputs[0]\n",
    "    # move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    final_prediction = np.argmax(logits, axis=-1).flatten()\n",
    "    predictions.append(final_prediction)\n",
    "    true_labels.append(label_ids)\n",
    "    \n",
    "print('total time used is: {0:.2f} s'.format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "51f50af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC Accuracy on Unseen Test Set: 0.94\n",
      "Linear SVC F1-Score on Unseen Test Set: 0.94\n",
      "Linear SVC Balanced Accuracy on Unseen Test Set: 0.92\n",
      "\n",
      "Linear SVC Classification Report on Unseen Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96     21914\n",
      "           1       0.89      0.89      0.89      7475\n",
      "\n",
      "    accuracy                           0.94     29389\n",
      "   macro avg       0.93      0.92      0.93     29389\n",
      "weighted avg       0.94      0.94      0.94     29389\n",
      "\n",
      "Linear SVC Confusion Matrix on Unseen Test Set:\n",
      "[[21104   810]\n",
      " [  846  6629]]\n"
     ]
    }
   ],
   "source": [
    "# convert numeric label to string\n",
    "final_prediction_list = np.concatenate(predictions)\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(test_labels_numbers, final_prediction_list)\n",
    "\n",
    "# Evaluate F1-score\n",
    "f1_score = f1_score(test_labels_numbers, final_prediction_list, average='weighted')\n",
    "\n",
    "# Evaluate balanced accuracy\n",
    "balanced_accuracy = balanced_accuracy_score(test_labels_numbers, final_prediction_list)\n",
    "\n",
    "\n",
    "# Print evaluation metrics for Linear SVC on the unseen test set\n",
    "print(\"Linear SVC Accuracy on Unseen Test Set:\", round(accuracy,2))\n",
    "print(\"Linear SVC F1-Score on Unseen Test Set:\", round(f1_score,2))\n",
    "print(\"Linear SVC Balanced Accuracy on Unseen Test Set:\", round(balanced_accuracy,2))\n",
    "print()\n",
    "\n",
    "# Print classification report and confusion matrix for Linear SVC on the unseen test set\n",
    "print(\"Linear SVC Classification Report on Unseen Test Set:\")\n",
    "print(classification_report(test_labels_numbers, final_prediction_list))\n",
    "\n",
    "print(\"Linear SVC Confusion Matrix on Unseen Test Set:\")\n",
    "print(confusion_matrix(test_labels_numbers, final_prediction_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d25d01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

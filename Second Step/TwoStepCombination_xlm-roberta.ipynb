{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80cd81b1",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79f916d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11170]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "import subprocess as sp\n",
    "import os\n",
    "def get_gpu_memory():\n",
    "    command = \"nvidia-smi --query-gpu=memory.free --format=csv\"\n",
    "    memory_free_info = sp.check_output(command.split()).decode('ascii').split('\\n')[:-1][1:]\n",
    "    memory_free_values = [int(x.split()[0]) for i, x in enumerate(memory_free_info)]\n",
    "    return memory_free_values\n",
    "\n",
    "get_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c20c53b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import json\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "with open('test_dataset.json', 'r') as fp:\n",
    "    test_dataset = json.load(fp)\n",
    "with open('train_dataset.json', 'r') as fp:\n",
    "    train_dataset = json.load(fp)\n",
    "f = open('/data/data_codebook.json')\n",
    "data_codebook = json.load(f)\n",
    "super_set={}\n",
    "for s in data_codebook:\n",
    "    if s[2]!=\"domain_name\":\n",
    "        if s[2] not in super_set:\n",
    "            super_set[s[2]]=[]\n",
    "        if s[5] not in super_set[s[2]]:\n",
    "            super_set[s[2]].append(s[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1536de84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
    "sw = stopwords.words('english')\n",
    "\n",
    "def clean_text(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", text) # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "\n",
    "    text = re.sub(r\"http\\S+\", \"\",text) #Removing URLs \n",
    "    #text = re.sub(r\"http\", \"\",text)\n",
    "    \n",
    "    html=re.compile(r'<.*?>') \n",
    "    \n",
    "    text = html.sub(r'',text) #Removing html tags\n",
    "    \n",
    "    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\" + '_'\n",
    "    for p in punctuations:\n",
    "        text = text.replace(p,'') #Removing punctuations\n",
    "        \n",
    "    text = [word.lower() for word in text.split() if word.lower() not in sw]\n",
    "    \n",
    "    text = \" \".join(text) #removing stopwords\n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text) #Removing emojis\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac8ed99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dataset_counts(dataset):\n",
    "    count_dataset = {\n",
    "        \"general\": {},\n",
    "        \"detailed\": {}\n",
    "    }\n",
    "    \n",
    "    for s in dataset:\n",
    "        detailed_label = s['detailed_label']\n",
    "        general_label = s[\"general_label\"]\n",
    "        \n",
    "        if detailed_label not in count_dataset[\"detailed\"]:\n",
    "            count_dataset[\"detailed\"][detailed_label] = 0\n",
    "        count_dataset[\"detailed\"][detailed_label] += 1\n",
    "\n",
    "        if general_label not in count_dataset[\"general\"]:\n",
    "            count_dataset[\"general\"][general_label] = 0\n",
    "        count_dataset[\"general\"][general_label] += 1\n",
    "    \n",
    "    return count_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebe0125",
   "metadata": {},
   "source": [
    "# RoBerta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0bae313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>detailed_label</th>\n",
       "      <th>general_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78983</th>\n",
       "      <td>Non-profit organizations with public particip...</td>\n",
       "      <td>Democracy</td>\n",
       "      <td>Freedom and Democracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44918</th>\n",
       "      <td>These measures do not contribute to solving r...</td>\n",
       "      <td>Education Expansion</td>\n",
       "      <td>Welfare and Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77212</th>\n",
       "      <td>We make it mandatory for the upper grades of ...</td>\n",
       "      <td>National Way of Life: Positive</td>\n",
       "      <td>Fabric of Society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3264</th>\n",
       "      <td>ensure that sheltered housing does not have t...</td>\n",
       "      <td>Welfare State Expansion</td>\n",
       "      <td>Welfare and Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50432</th>\n",
       "      <td>But sand extraction in the Øresund contribute...</td>\n",
       "      <td>Environmental Protection</td>\n",
       "      <td>Welfare and Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26960</th>\n",
       "      <td>II. Active measures to improve the well-being...</td>\n",
       "      <td>Equality: Positive</td>\n",
       "      <td>Welfare and Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31090</th>\n",
       "      <td>PSD understands that one of the central axes ...</td>\n",
       "      <td>Culture: Positive</td>\n",
       "      <td>Welfare and Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79145</th>\n",
       "      <td>On that basis, the orientation towards Croati...</td>\n",
       "      <td>Democracy</td>\n",
       "      <td>Freedom and Democracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29653</th>\n",
       "      <td>sp.a wants our society to become accessible i...</td>\n",
       "      <td>Equality: Positive</td>\n",
       "      <td>Welfare and Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49426</th>\n",
       "      <td>Legal acts for the implementation of projects...</td>\n",
       "      <td>Environmental Protection</td>\n",
       "      <td>Welfare and Quality of Life</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84860 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  \\\n",
       "78983   Non-profit organizations with public particip...   \n",
       "44918   These measures do not contribute to solving r...   \n",
       "77212   We make it mandatory for the upper grades of ...   \n",
       "3264    ensure that sheltered housing does not have t...   \n",
       "50432   But sand extraction in the Øresund contribute...   \n",
       "...                                                  ...   \n",
       "26960   II. Active measures to improve the well-being...   \n",
       "31090   PSD understands that one of the central axes ...   \n",
       "79145   On that basis, the orientation towards Croati...   \n",
       "29653   sp.a wants our society to become accessible i...   \n",
       "49426   Legal acts for the implementation of projects...   \n",
       "\n",
       "                       detailed_label                general_label  \n",
       "78983                       Democracy        Freedom and Democracy  \n",
       "44918             Education Expansion  Welfare and Quality of Life  \n",
       "77212  National Way of Life: Positive            Fabric of Society  \n",
       "3264          Welfare State Expansion  Welfare and Quality of Life  \n",
       "50432        Environmental Protection  Welfare and Quality of Life  \n",
       "...                               ...                          ...  \n",
       "26960              Equality: Positive  Welfare and Quality of Life  \n",
       "31090               Culture: Positive  Welfare and Quality of Life  \n",
       "79145                       Democracy        Freedom and Democracy  \n",
       "29653              Equality: Positive  Welfare and Quality of Life  \n",
       "49426        Environmental Protection  Welfare and Quality of Life  \n",
       "\n",
       "[84860 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataframe=[]\n",
    "for k,v in test_dataset.items():\n",
    "    for key, value in super_set.items():\n",
    "        if k in value:\n",
    "            super_label = key\n",
    "    for s in v:\n",
    "            per_line_dict = {}\n",
    "            per_line_dict[\"sentence\"] = s\n",
    "            per_line_dict[\"detailed_label\"] = k\n",
    "            per_line_dict[\"general_label\"] = super_label\n",
    "            test_dataframe.append(per_line_dict)\n",
    "\n",
    "test_dataframe = pd.DataFrame(data=(test_dataframe))\n",
    "test_dataframe=shuffle(test_dataframe).dropna()\n",
    "test_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6aea2740",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences_cleaned=[]\n",
    "for s in list(test_dataframe[\"sentence\"]):\n",
    "    cleaned=clean_text(s)\n",
    "    test_sentences_cleaned.append(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ec1a2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  151\n",
      "min:  2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, XLMRobertaForSequenceClassification\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
    "# tokenize the text feature \n",
    "test_tokenized_feature = tokenizer.batch_encode_plus(\n",
    "                            # Sentences to encode\n",
    "                            test_sentences_cleaned, \n",
    "                            # Add '[CLS]' and '[SEP]'\n",
    "                            add_special_tokens = True      \n",
    "                   )\n",
    "# collect tokenized sentence length \n",
    "token_sentence_length = [len(x) for x in test_tokenized_feature['input_ids']]\n",
    "print('max: ', max(token_sentence_length))\n",
    "print('min: ', min(token_sentence_length))\n",
    "MAX_LEN=max(token_sentence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "592614da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72240cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                sentence  \\\n",
      "4736                                 loss of autonomy or   \n",
      "52959   We will increase public awareness of environm...   \n",
      "27513   Support the use of gender quotas to gain a ge...   \n",
      "60994   Emphasis will be placed on preparing young pe...   \n",
      "35823   —and the laws that do exist are poorly enforced.   \n",
      "\n",
      "                        detailed_label                general_label  \\\n",
      "4736           Welfare State Expansion  Welfare and Quality of Life   \n",
      "52959         Environmental Protection  Welfare and Quality of Life   \n",
      "27513               Equality: Positive  Welfare and Quality of Life   \n",
      "60994  Non-economic Demographic Groups                Social Groups   \n",
      "35823          Law and Order: Positive            Fabric of Society   \n",
      "\n",
      "       predicted_general_label  predicted_detailed_label  \n",
      "4736                         0                         0  \n",
      "52959                        1                         1  \n",
      "27513                        1                         0  \n",
      "60994                        1                         0  \n",
      "35823                        0                         0  \n"
     ]
    }
   ],
   "source": [
    "# Determine the device (GPU or CPU)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the tokenizers for the general and detailed label identifiers\n",
    "tokenizer_general = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
    "tokenizer_detailed = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
    "\n",
    "# Load the general label model weights\n",
    "model_general = torch.load('Roberta_40percent_TwoStep_General', map_location=device)  # Load the model on the same device as determined above\n",
    "\n",
    "# Load the detailed label model weights\n",
    "model_detailed = torch.load('Roberta_30percent_TwoStep_Detailed', map_location=device)  # Load the model on the same device as determined above\n",
    "\n",
    "# Put the models in evaluation mode\n",
    "model_general.eval()\n",
    "model_detailed.eval()\n",
    "\n",
    "# Lists to store predicted labels\n",
    "predicted_general_labels = []\n",
    "predicted_detailed_labels = []\n",
    "\n",
    "# Iterate through test data\n",
    "for index, row in test_dataframe.iterrows():\n",
    "    # Get the sentence and general label from the test data\n",
    "    sample_sentence = row['sentence']\n",
    "    cleaned_sentence=clean_text(sample_sentence)\n",
    "    general_label = row['general_label']\n",
    "    general_label_number = 1 if general_label == 'Welfare and Quality of Life' else 0 \n",
    "    # Tokenize the sample sentence\n",
    "    input_ids = tokenizer_general.encode(cleaned_sentence,  max_length = MAX_LEN, add_special_tokens=True, truncation=True, padding=True, return_tensors='pt').to(device)\n",
    "    \n",
    "    # Perform inference with the general label model\n",
    "    with torch.no_grad():\n",
    "        general_outputs = model_general(input_ids)\n",
    "        general_logits = general_outputs.logits\n",
    "        general_probabilities = torch.softmax(general_logits, dim=1)\n",
    "        general_predicted_label = torch.argmax(general_probabilities, dim=1).item()\n",
    "    \n",
    "    # Append the predicted general label to the list\n",
    "    predicted_general_labels.append(general_predicted_label)\n",
    "    \n",
    "    # Determine if the detailed model should be used based on the general label\n",
    "    if general_predicted_label==1 :\n",
    "        # Tokenize the sample sentence for the detailed label model\n",
    "        input_ids_detailed = tokenizer_detailed.encode(cleaned_sentence,  max_length = MAX_LEN, add_special_tokens=True, truncation=True, padding=True, return_tensors='pt').to(device)\n",
    "        \n",
    "        # Perform inference with the detailed label model\n",
    "        with torch.no_grad():\n",
    "            detailed_outputs = model_detailed(input_ids_detailed)\n",
    "            detailed_logits = detailed_outputs.logits\n",
    "            detailed_probabilities = torch.softmax(detailed_logits, dim=1)\n",
    "            detailed_predicted_label = torch.argmax(detailed_probabilities, dim=1).item()\n",
    "    else:\n",
    "        # If the general label doesn't match the criteria, set detailed prediction to None\n",
    "        detailed_predicted_label = 0\n",
    "    \n",
    "    # Append the predicted detailed label to the list\n",
    "    predicted_detailed_labels.append(detailed_predicted_label)\n",
    "\n",
    "# Add the predicted labels to your test_dataframe\n",
    "test_dataframe['predicted_general_label'] = predicted_general_labels\n",
    "test_dataframe['predicted_detailed_label'] = predicted_detailed_labels\n",
    "\n",
    "# Print the updated dataframe with predicted labels\n",
    "print(test_dataframe.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fa87750c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels_numbers=[]\n",
    "for s in list(test_dataframe[\"general_label\"]):\n",
    "    if s=='Welfare and Quality of Life':\n",
    "        number=1\n",
    "    else:\n",
    "        number=0\n",
    "    test_labels_numbers.append(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "02482dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC Accuracy on Unseen Test Set: 0.69\n",
      "Linear SVC F1-Score on Unseen Test Set: 0.61\n",
      "Linear SVC Balanced Accuracy on Unseen Test Set: 0.56\n",
      "\n",
      "Linear SVC Classification Report on Unseen Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.96      0.80     55471\n",
      "           1       0.71      0.16      0.26     29389\n",
      "\n",
      "    accuracy                           0.69     84860\n",
      "   macro avg       0.70      0.56      0.53     84860\n",
      "weighted avg       0.69      0.69      0.61     84860\n",
      "\n",
      "Linear SVC Confusion Matrix on Unseen Test Set:\n",
      "[[53529  1942]\n",
      " [24637  4752]]\n"
     ]
    }
   ],
   "source": [
    "# convert numeric label to string\n",
    "final_prediction_list = list(test_dataframe[\"predicted_detailed_label\"])\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(test_labels_numbers, final_prediction_list)\n",
    "\n",
    "# Evaluate F1-score\n",
    "f1_score = f1_score(test_labels_numbers, final_prediction_list, average='weighted')\n",
    "\n",
    "# Evaluate balanced accuracy\n",
    "balanced_accuracy = balanced_accuracy_score(test_labels_numbers, final_prediction_list)\n",
    "\n",
    "\n",
    "# Print evaluation metrics for Linear SVC on the unseen test set\n",
    "print(\"Linear SVC Accuracy on Unseen Test Set:\", round(accuracy,2))\n",
    "print(\"Linear SVC F1-Score on Unseen Test Set:\", round(f1_score,2))\n",
    "print(\"Linear SVC Balanced Accuracy on Unseen Test Set:\", round(balanced_accuracy,2))\n",
    "print()\n",
    "\n",
    "# Print classification report and confusion matrix for Linear SVC on the unseen test set\n",
    "print(\"Linear SVC Classification Report on Unseen Test Set:\")\n",
    "print(classification_report(test_labels_numbers, final_prediction_list))\n",
    "\n",
    "print(\"Linear SVC Confusion Matrix on Unseen Test Set:\")\n",
    "print(confusion_matrix(test_labels_numbers, final_prediction_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6c6f19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

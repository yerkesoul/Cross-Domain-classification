{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80cd81b1",
   "metadata": {},
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79f916d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11170]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "import subprocess as sp\n",
    "import os\n",
    "def get_gpu_memory():\n",
    "    command = \"nvidia-smi --query-gpu=memory.free --format=csv\"\n",
    "    memory_free_info = sp.check_output(command.split()).decode('ascii').split('\\n')[:-1][1:]\n",
    "    memory_free_values = [int(x.split()[0]) for i, x in enumerate(memory_free_info)]\n",
    "    return memory_free_values\n",
    "\n",
    "get_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c20c53b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import json\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "with open('test_dataset.json', 'r') as fp:\n",
    "    test_dataset = json.load(fp)\n",
    "with open('train_dataset.json', 'r') as fp:\n",
    "    train_dataset = json.load(fp)\n",
    "f = open('/data/data_codebook.json')\n",
    "data_codebook = json.load(f)\n",
    "super_set={}\n",
    "for s in data_codebook:\n",
    "    if s[2]!=\"domain_name\":\n",
    "        if s[2] not in super_set:\n",
    "            super_set[s[2]]=[]\n",
    "        if s[5] not in super_set[s[2]]:\n",
    "            super_set[s[2]].append(s[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1536de84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, balanced_accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
    "sw = stopwords.words('english')\n",
    "\n",
    "def clean_text(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    text = re.sub(r\"[^a-zA-Z?.!,Â¿]+\", \" \", text) # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "\n",
    "    text = re.sub(r\"http\\S+\", \"\",text) #Removing URLs \n",
    "    #text = re.sub(r\"http\", \"\",text)\n",
    "    \n",
    "    html=re.compile(r'<.*?>') \n",
    "    \n",
    "    text = html.sub(r'',text) #Removing html tags\n",
    "    \n",
    "    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\" + '_'\n",
    "    for p in punctuations:\n",
    "        text = text.replace(p,'') #Removing punctuations\n",
    "        \n",
    "    text = [word.lower() for word in text.split() if word.lower() not in sw]\n",
    "    \n",
    "    text = \" \".join(text) #removing stopwords\n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    text = emoji_pattern.sub(r'', text) #Removing emojis\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac8ed99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dataset_counts(dataset):\n",
    "    count_dataset = {\n",
    "        \"general\": {},\n",
    "        \"detailed\": {}\n",
    "    }\n",
    "    \n",
    "    for s in dataset:\n",
    "        detailed_label = s['detailed_label']\n",
    "        general_label = s[\"general_label\"]\n",
    "        \n",
    "        if detailed_label not in count_dataset[\"detailed\"]:\n",
    "            count_dataset[\"detailed\"][detailed_label] = 0\n",
    "        count_dataset[\"detailed\"][detailed_label] += 1\n",
    "\n",
    "        if general_label not in count_dataset[\"general\"]:\n",
    "            count_dataset[\"general\"][general_label] = 0\n",
    "        count_dataset[\"general\"][general_label] += 1\n",
    "    \n",
    "    return count_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8332aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_custom_dataset(balanced_dataset, total_limit, desired_percentage):\n",
    "    used_sentences = set()\n",
    "    dataset = []\n",
    "    welfare_count = 0\n",
    "    welfare_limit = int(total_limit * desired_percentage)\n",
    "    category_limits = {category: 100 for category in balanced_dataset.keys()}\n",
    "\n",
    "    # Calculate the total number of sentences in the dataset\n",
    "    total_sentences = sum(len(v) for v in balanced_dataset.values())\n",
    "\n",
    "    # First, add sentences from 'Environmental Protection'\n",
    "    for sentence in balanced_dataset['Environmental Protection']:\n",
    "        if len(dataset) >= welfare_limit:\n",
    "            break\n",
    "\n",
    "        if sentence not in used_sentences:\n",
    "            per_line_dict = {\n",
    "                \"sentence\": sentence,\n",
    "                \"detailed_label\": 'Environmental Protection',\n",
    "                \"general_label\": 'Welfare and Quality of Life'\n",
    "            }\n",
    "            dataset.append(per_line_dict)\n",
    "            used_sentences.add(sentence)\n",
    "            welfare_count += 1\n",
    "\n",
    "    # Then, add sentences from other categories\n",
    "    while len(dataset) < total_limit:\n",
    "        for category, sentences in balanced_dataset.items():\n",
    "            if len(dataset) >= total_limit:\n",
    "                break\n",
    "            if category != 'Environmental Protection':\n",
    "                for key, value in super_set.items():\n",
    "                    if category in value:\n",
    "                        super_label = key\n",
    "\n",
    "                category_limit = min(len(sentences), category_limits[category])\n",
    "\n",
    "                limit = min(100, category_limit)\n",
    "\n",
    "                for sentence in sentences:\n",
    "                    if limit == 0 or len(dataset) >= total_limit:\n",
    "                        break\n",
    "\n",
    "                    if sentence not in used_sentences:\n",
    "                        per_line_dict = {\n",
    "                            \"sentence\": sentence,\n",
    "                            \"detailed_label\": category,\n",
    "                            \"general_label\": super_label\n",
    "                        }\n",
    "                        dataset.append(per_line_dict)\n",
    "                        used_sentences.add(sentence)\n",
    "                        limit -= 1\n",
    "                        category_limits[category] += 100\n",
    "\n",
    "    return dataset, welfare_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d91ecea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences in the dataset: 56000\n",
      "Sentences with 'Welfare and Quality of Life' label: 5600\n",
      "{'Welfare and Quality of Life': 9826, 'Economy': 11514, 'Fabric of Society': 13523, 'Social Groups': 3173, 'External Relations': 6903, 'Freedom and Democracy': 5980, 'Political System': 5081}\n",
      "56000\n",
      "116\n",
      "{'Environmental Protection': 5600, 'Welfare State Expansion': 700, 'Nationalisation': 700, 'Multiculturalism: Positive': 700, 'Agriculture and Farmers: Positive': 700, 'Incentives: Positive': 700, 'Market Regulation': 700, 'Economic Orthodoxy': 700, 'Technology and Infrastructure: Positive': 700, 'Equality: Positive': 700, 'Culture: Positive': 700, 'Military: Positive': 700, 'Freedom and Human Rights': 700, 'Law and Order: Positive': 700, 'Internationalism: Positive': 700, 'Education Expansion': 700, 'Political Authority: Party Competence': 700, 'Decentralization': 700, 'Free Market Economy': 700, 'Governmental and Administrative Efficiency': 700, 'Civic Mindedness General: Positive': 700, 'Law and Order: Negative': 700, 'Non-economic Demographic Groups': 700, 'Human Rights': 700, 'Political Corruption': 700, 'Traditional Morality: Negative': 700, 'Constitutionalism: Negative': 700, 'European Community/Union: Positive': 700, 'Economic Planning': 700, 'Political Authority': 700, 'Economic Growth: Positive': 700, 'Democracy General: Positive': 700, 'Economic Goals': 700, 'Anti-Growth Economy: Positive': 700, 'Middle Class and Professional Groups': 700, 'Sustainability: Positive': 700, 'Traditional Morality: Positive': 700, 'National Way of Life: Immigration: Negative': 700, 'Multiculturalism General: Positive': 700, 'National Way of Life General: Positive': 700, 'National Way of Life: Immigration: Positive': 700, 'National Way of Life: Positive': 700, 'Direct Democracy: Positive': 645, 'National Way of Life General: Negative': 600, 'Welfare State Limitation': 600, 'Underprivileged Minority Groups': 600, 'Democracy': 600, 'Freedom': 600, 'Constitutionalism: Positive': 600, 'Multiculturalism: Negative': 600, 'Education Limitation': 515, 'Multiculturalism: Immigrants Assimilation': 407, 'Protectionism: Positive': 600, 'Military: Negative': 600, 'European Community/Union: Negative': 600, 'Anti-Imperialism: Foreign Financial Influence': 600, 'Civic Mindedness: Positive': 600, 'Protectionism: Negative': 600, 'Corporatism/Mixed Economy': 600, 'Centralisation': 600, 'Political Authority: Strong government': 371, 'Keynesian Demand Management': 600, 'Agriculture and Farmers: Negative': 182, 'Internationalism: Negative': 600, 'Multiculturalism General: Negative': 600, 'Foreign Special Relationships: Positive': 600, 'Controlled Economy': 600, 'Property-Restitution: Positive': 25, 'Private-Public Mix in Welfare: Positive': 227, 'Peace': 600, 'Political Authority: Personal Competence': 347, 'Anti-Imperialism': 442, 'Foreign Special Relationships: Negative': 600, 'Civic Mindedness: Bottom-Up Activism': 569, 'Multiculturalism: Immigrants Diversity': 600, 'Cyprus Issue': 472, 'Multiculturalism: Indigenous rights: Positive': 496, 'Privatisation: Negative': 16, 'Transition: Pre-Democratic Elites: Negative': 134, 'Russia/USSR/CIS: Positive': 26, 'Marxist Analysis': 600, 'National Way of Life: Negative': 600, 'General Crisis': 58, 'Representative Democracy: Positive': 594, 'Democracy General: Negative': 122, 'Independence: Positive': 42, 'War Participants: Positive': 142, 'Transition: Rehabilitation and Compensation': 46, 'Minorities Abroad: Positive': 78, 'Control of Economy: Negative': 126, 'Multiculturalism: Indigenous rights: Negative': 41, 'Private-Public Mix in Culture: Positive': 36, 'Communist: Negative': 46, 'Rights of Nations: Positive': 1, 'Transition: Pre-Democratic Elites: Positive': 1, 'Public Situation: Negative': 9, 'National Security: Positive': 175, 'Mixed Economy: Positive': 25, 'SFR Yugoslavia: Positive': 52, 'Private-Public Mix in Education: Positive': 47, 'Political Coalitions: Positive': 18, 'Restrictive Citizenship: Positive': 6, 'Refugees: Positive': 71, 'Russia/USSR/CIS: Negative': 7, 'Transition to Democracy': 13, 'Western States: Positive': 22, 'Publicly-Owned Industry: Positive': 12, 'Socialist Property: Positive': 3, 'Property-Restitution: Negative': 5, 'Nordic Council: Positive': 4, 'Rehabilitation and Compensation: Positive': 8, 'Eastern European Countries: Positive': 7, 'Cultural Autonomy: Positive': 5, 'Communist: Positive': 1, 'Social Ownership: Positive': 2, 'Private-Public Mix in Social Justice: Positive': 1}\n"
     ]
    }
   ],
   "source": [
    "\"Experiment 1\"\n",
    "total_limit = 56000\n",
    "desired_percentage = 0.10\n",
    "\n",
    "dataset, welfare_count = create_custom_dataset(train_dataset, total_limit, desired_percentage)\n",
    "\n",
    "print(\"Total sentences in the dataset:\", len(dataset))\n",
    "print(\"Sentences with 'Welfare and Quality of Life' label:\", welfare_count)\n",
    "\n",
    "# Usage example:\n",
    "# Assuming you have the 'dataset' variable containing the dataset obtained from the create_custom_dataset function\n",
    "# Replace this with the actual dataset you want to count.\n",
    "count_dataset = calculate_dataset_counts(dataset)\n",
    "print(count_dataset[\"general\"])\n",
    "print(sum(count_dataset[\"general\"].values()))\n",
    "print(len(count_dataset[\"detailed\"].keys()))\n",
    "print(count_dataset[\"detailed\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebe0125",
   "metadata": {},
   "source": [
    "# RoBerta model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49afe225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tokens\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "226eee6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>detailed_label</th>\n",
       "      <th>general_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6798</th>\n",
       "      <td>From patients who passively undergo to self-r...</td>\n",
       "      <td>Freedom and Human Rights</td>\n",
       "      <td>Freedom and Democracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32499</th>\n",
       "      <td>Taking up a course of study must ensure the r...</td>\n",
       "      <td>Human Rights</td>\n",
       "      <td>Freedom and Democracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19922</th>\n",
       "      <td>The US armed forces are guaranteed total impu...</td>\n",
       "      <td>Military: Negative</td>\n",
       "      <td>External Relations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10073</th>\n",
       "      <td>These young people seize their opportunities ...</td>\n",
       "      <td>Underprivileged Minority Groups</td>\n",
       "      <td>Social Groups</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51884</th>\n",
       "      <td>These must have reasonable conditions and con...</td>\n",
       "      <td>Welfare State Expansion</td>\n",
       "      <td>Welfare and Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52815</th>\n",
       "      <td>preservation of cultural identity, and cultur...</td>\n",
       "      <td>Culture: Positive</td>\n",
       "      <td>Welfare and Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30364</th>\n",
       "      <td>Why energy poverty?</td>\n",
       "      <td>Nationalisation</td>\n",
       "      <td>Economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19706</th>\n",
       "      <td>Not only does the accumulation of immigrants ...</td>\n",
       "      <td>Multiculturalism: Immigrants Assimilation</td>\n",
       "      <td>Fabric of Society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48730</th>\n",
       "      <td>and ensuring mother tongue teaching in school...</td>\n",
       "      <td>Multiculturalism General: Positive</td>\n",
       "      <td>Fabric of Society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26544</th>\n",
       "      <td>For this, it is necessary to base oneself bot...</td>\n",
       "      <td>National Way of Life: Immigration: Positive</td>\n",
       "      <td>Fabric of Society</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55999 rows Ã 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  \\\n",
       "6798    From patients who passively undergo to self-r...   \n",
       "32499   Taking up a course of study must ensure the r...   \n",
       "19922   The US armed forces are guaranteed total impu...   \n",
       "10073   These young people seize their opportunities ...   \n",
       "51884   These must have reasonable conditions and con...   \n",
       "...                                                  ...   \n",
       "52815   preservation of cultural identity, and cultur...   \n",
       "30364                                Why energy poverty?   \n",
       "19706   Not only does the accumulation of immigrants ...   \n",
       "48730   and ensuring mother tongue teaching in school...   \n",
       "26544   For this, it is necessary to base oneself bot...   \n",
       "\n",
       "                                    detailed_label  \\\n",
       "6798                      Freedom and Human Rights   \n",
       "32499                                 Human Rights   \n",
       "19922                           Military: Negative   \n",
       "10073              Underprivileged Minority Groups   \n",
       "51884                      Welfare State Expansion   \n",
       "...                                            ...   \n",
       "52815                            Culture: Positive   \n",
       "30364                              Nationalisation   \n",
       "19706    Multiculturalism: Immigrants Assimilation   \n",
       "48730           Multiculturalism General: Positive   \n",
       "26544  National Way of Life: Immigration: Positive   \n",
       "\n",
       "                     general_label  \n",
       "6798         Freedom and Democracy  \n",
       "32499        Freedom and Democracy  \n",
       "19922           External Relations  \n",
       "10073                Social Groups  \n",
       "51884  Welfare and Quality of Life  \n",
       "...                            ...  \n",
       "52815  Welfare and Quality of Life  \n",
       "30364                      Economy  \n",
       "19706            Fabric of Society  \n",
       "48730            Fabric of Society  \n",
       "26544            Fabric of Society  \n",
       "\n",
       "[55999 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe = pd.DataFrame(data=(dataset))\n",
    "dataframe=shuffle(dataframe).dropna()\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b6ec85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences=list(dataframe[\"sentence\"])\n",
    "train_labels=[]\n",
    "for s in list(dataframe[\"detailed_label\"]):\n",
    "    if s=='Environmental Protection':\n",
    "        number=1\n",
    "    else:\n",
    "        number=0\n",
    "    train_labels.append(number)\n",
    "len(train_sentences)==len(train_labels)\n",
    "\n",
    "train_sentences_cleaned=[]\n",
    "for s in list(dataframe[\"sentence\"]):\n",
    "    cleaned=clean_text(s)\n",
    "    train_sentences_cleaned.append(cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "62bdc231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  135\n",
      "min:  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'The distribution of sequence length, when the percentage of Welfare sentences is: 10.0%')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenize the text feature \n",
    "tokenized_feature_raw = tokenizer.batch_encode_plus(\n",
    "                            # Sentences to encode\n",
    "                            train_sentences_cleaned, \n",
    "                            # Add '[CLS]' and '[SEP]'\n",
    "                            add_special_tokens = True      \n",
    "                   )\n",
    "# collect tokenized sentence length \n",
    "token_sentence_length = [len(x) for x in tokenized_feature_raw['input_ids']]\n",
    "print('max: ', max(token_sentence_length))\n",
    "print('min: ', min(token_sentence_length))\n",
    "# plot the distribution\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.hist(token_sentence_length, rwidth = 0.9)\n",
    "plt.xlabel('Sequence Length', fontsize = 18)\n",
    "plt.ylabel('Number of Samples', fontsize = 18)\n",
    "plt.xticks(fontsize = 14)\n",
    "plt.yticks(fontsize = 14)\n",
    "plt.title(\"The distribution of sequence length, when the percentage of Welfare sentences is: \"+str(desired_percentage*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49e63e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize features \n",
    "MAX_LEN = 135\n",
    "tokenized_feature = tokenizer.batch_encode_plus(\n",
    "                            # Sentences to encode\n",
    "                            train_sentences_cleaned, \n",
    "                            # Add '[CLS]' and '[SEP]'\n",
    "                            add_special_tokens = True,\n",
    "                            # Add empty tokens if len(text)<MAX_LEN\n",
    "                            padding = 'max_length',\n",
    "                            # Truncate all sentences to max length\n",
    "                            truncation=True,\n",
    "                            # Set the maximum length\n",
    "                            max_length = MAX_LEN, \n",
    "                            # Return attention mask\n",
    "                            return_attention_mask = True,\n",
    "                            # Return pytorch tensors\n",
    "                            return_tensors = 'pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "361641ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 80% for training and 20% for validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_inputs, validation_inputs, train_labels, validation_labels, train_masks, validation_masks = train_test_split(tokenized_feature['input_ids'], \n",
    "                                                                                                             train_labels,\n",
    "                                                                                                                    tokenized_feature['attention_mask'],\n",
    "                                                                                                      random_state=42, test_size=0.2, stratify=train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "329cf7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load base package for the tasks from pytorch\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "# define batch_size\n",
    "batch_size = 16\n",
    "# Create the DataLoader for our training set\n",
    "train_data = TensorDataset(train_inputs, train_masks, torch.tensor(train_labels))\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "# Create the DataLoader for our test set\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, torch.tensor(validation_labels))\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d468d2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# BertForSequenceClassification\n",
    "from transformers import XLMRobertaForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
    "model = XLMRobertaForSequenceClassification.from_pretrained(\n",
    "    \"xlm-roberta-base\", \n",
    "    # Specify number of classes\n",
    "    num_labels = len(set(train_labels)), \n",
    "    # Whether the model returns attentions weights\n",
    "    output_attentions = False,\n",
    "    # Whether the model returns all hidden-states \n",
    "    output_hidden_states = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73091f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are resizing the embedding layer without providing a `pad_to_multiple_of` parameter. This means that the new embeding dimension will be 250002. This might induce some performance reduction as *Tensor Cores* will not be available. For more details  about this, or help on choosing the correct value for resizing, refer to this guide: https://docs.nvidia.com/deeplearning/performance/dl-performance-matrix-multiplication/index.html#requirements-tc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(250002, 768, padding_idx=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Receive the full size of the new word\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a73d782",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/yabdul/.local/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Optimizer & Learning Rate Scheduler\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, \n",
    "                  eps = 1e-8 \n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a3043c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of training epochs\n",
    "epochs = 3\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "# Create the learning rate scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f366a34b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XLMRobertaForSequenceClassification(\n",
       "  (roberta): XLMRobertaModel(\n",
       "    (embeddings): XLMRobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): XLMRobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): XLMRobertaLayer(\n",
       "          (attention): XLMRobertaAttention(\n",
       "            (self): XLMRobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): XLMRobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): XLMRobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): XLMRobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): XLMRobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tell pytorch to run this model on GPU\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23de45ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ebc3e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "import time\n",
    "import datetime\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "torch.cuda.empty_cache()\n",
    "# start training from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c83f4751",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 3 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.21\n",
      "  Training epcoh took: 0:12:43\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.94\n",
      "\n",
      "======== Epoch 2 / 3 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.17\n",
      "  Training epcoh took: 0:12:43\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.94\n",
      "\n",
      "======== Epoch 3 / 3 ========\n",
      "Training...\n",
      "\n",
      "  Average training loss: 0.15\n",
      "  Training epcoh took: 0:12:43\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.94\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:41:40 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "seed_val = 42\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    # Perform one full pass over the training set.\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the device using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)        \n",
    "        loss = output.loss\n",
    "        total_train_loss += loss.item()\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    t0 = time.time()\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    best_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "        # Tell pytorch not to bother with constructing the compute graph during\n",
    "        # the forward pass, since this is only needed for backprop (training).\n",
    "        with torch.no_grad():        \n",
    "            output= model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "        loss = output.loss\n",
    "        total_eval_loss += loss.item()\n",
    "        # Move logits and labels to CPU if we are using GPU\n",
    "        logits = output.logits\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        # Calculate the accuracy for this batch of test sentences, and\n",
    "        # accumulate it over all batches.\n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    if avg_val_accuracy > best_eval_accuracy:\n",
    "        torch.save(model, 'Roberta_10percent_OneStep')\n",
    "        best_eval_accuracy = avg_val_accuracy\n",
    "    #print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    #print(\"  Validation took: {:}\".format(validation_time))\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "063c2b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('Roberta_10percent_OneStep')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574c6b8b",
   "metadata": {},
   "source": [
    "# Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d0bae313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Now test the model on another unseen test sets--------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>detailed_label</th>\n",
       "      <th>general_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34656</th>\n",
       "      <td>- We will therefore continue to resolutely op...</td>\n",
       "      <td>Freedom and Human Rights</td>\n",
       "      <td>Freedom and Democracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33707</th>\n",
       "      <td>14) DR-DPA advocates the inclusion of the Repu...</td>\n",
       "      <td>Military: Positive</td>\n",
       "      <td>External Relations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71175</th>\n",
       "      <td>However, the PS would like us to step up effo...</td>\n",
       "      <td>Economic Goals</td>\n",
       "      <td>Economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17484</th>\n",
       "      <td>This philosophy should permeate all actors in...</td>\n",
       "      <td>Economic Orthodoxy</td>\n",
       "      <td>Economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8131</th>\n",
       "      <td>2) Contractual provision in a support and fol...</td>\n",
       "      <td>Welfare State Expansion</td>\n",
       "      <td>Welfare and Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6265</th>\n",
       "      <td>In the first phase, the privatization of the ...</td>\n",
       "      <td>Welfare State Expansion</td>\n",
       "      <td>Welfare and Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54886</th>\n",
       "      <td>The Left Alliance demands a halt to climate c...</td>\n",
       "      <td>Environmental Protection</td>\n",
       "      <td>Welfare and Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76820</th>\n",
       "      <td>Proposition 340: Provide Adequate Protection ...</td>\n",
       "      <td>National Way of Life: Immigration: Positive</td>\n",
       "      <td>Fabric of Society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>Social security is a constitutional category, ...</td>\n",
       "      <td>Welfare State Expansion</td>\n",
       "      <td>Welfare and Quality of Life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>This will prevent real estate foreclosures in...</td>\n",
       "      <td>Market Regulation</td>\n",
       "      <td>Economy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84860 rows Ã 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence  \\\n",
       "34656   - We will therefore continue to resolutely op...   \n",
       "33707  14) DR-DPA advocates the inclusion of the Repu...   \n",
       "71175   However, the PS would like us to step up effo...   \n",
       "17484   This philosophy should permeate all actors in...   \n",
       "8131    2) Contractual provision in a support and fol...   \n",
       "...                                                  ...   \n",
       "6265    In the first phase, the privatization of the ...   \n",
       "54886   The Left Alliance demands a halt to climate c...   \n",
       "76820   Proposition 340: Provide Adequate Protection ...   \n",
       "860    Social security is a constitutional category, ...   \n",
       "15795   This will prevent real estate foreclosures in...   \n",
       "\n",
       "                                    detailed_label  \\\n",
       "34656                     Freedom and Human Rights   \n",
       "33707                           Military: Positive   \n",
       "71175                               Economic Goals   \n",
       "17484                           Economic Orthodoxy   \n",
       "8131                       Welfare State Expansion   \n",
       "...                                            ...   \n",
       "6265                       Welfare State Expansion   \n",
       "54886                     Environmental Protection   \n",
       "76820  National Way of Life: Immigration: Positive   \n",
       "860                        Welfare State Expansion   \n",
       "15795                            Market Regulation   \n",
       "\n",
       "                     general_label  \n",
       "34656        Freedom and Democracy  \n",
       "33707           External Relations  \n",
       "71175                      Economy  \n",
       "17484                      Economy  \n",
       "8131   Welfare and Quality of Life  \n",
       "...                            ...  \n",
       "6265   Welfare and Quality of Life  \n",
       "54886  Welfare and Quality of Life  \n",
       "76820            Fabric of Society  \n",
       "860    Welfare and Quality of Life  \n",
       "15795                      Economy  \n",
       "\n",
       "[84860 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"-----Now test the model on another unseen test sets--------\")\n",
    "test_dataframe=[]\n",
    "for k,v in test_dataset.items():\n",
    "    for key, value in super_set.items():\n",
    "        if k in value:\n",
    "            super_label = key\n",
    "    for s in v:\n",
    "            per_line_dict = {}\n",
    "            per_line_dict[\"sentence\"] = s\n",
    "            per_line_dict[\"detailed_label\"] = k\n",
    "            per_line_dict[\"general_label\"] = super_label\n",
    "            test_dataframe.append(per_line_dict)\n",
    "\n",
    "test_dataframe = pd.DataFrame(data=(test_dataframe))\n",
    "test_dataframe=shuffle(test_dataframe).dropna()\n",
    "test_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6aea2740",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences_cleaned=[]\n",
    "for s in list(test_dataframe[\"sentence\"]):\n",
    "    cleaned=clean_text(s)\n",
    "    test_sentences_cleaned.append(cleaned)\n",
    "\n",
    "test_labels_numbers=[]\n",
    "for s in list(test_dataframe[\"detailed_label\"]):\n",
    "    if s=='Environmental Protection':\n",
    "        number=1\n",
    "    else:\n",
    "        number=0\n",
    "    test_labels_numbers.append(number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c14491a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_sentences_cleaned)==len(test_labels_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ec1a2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max:  151\n",
      "min:  2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Test set.The distribution of sequence length, when the percentage of Welfare sentences is: 10.0%')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tokenize the text feature \n",
    "test_tokenized_feature = tokenizer.batch_encode_plus(\n",
    "                            # Sentences to encode\n",
    "                            test_sentences_cleaned, \n",
    "                            # Add '[CLS]' and '[SEP]'\n",
    "                            add_special_tokens = True      \n",
    "                   )\n",
    "# collect tokenized sentence length \n",
    "token_sentence_length = [len(x) for x in test_tokenized_feature['input_ids']]\n",
    "print('max: ', max(token_sentence_length))\n",
    "print('min: ', min(token_sentence_length))\n",
    "# plot the distribution\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20, 8))\n",
    "plt.hist(token_sentence_length, rwidth = 0.9)\n",
    "plt.xlabel('Sequence Length', fontsize = 18)\n",
    "plt.ylabel('Number of Samples', fontsize = 18)\n",
    "plt.xticks(fontsize = 14)\n",
    "plt.yticks(fontsize = 14)\n",
    "plt.title(\"Test set.The distribution of sequence length, when the percentage of Welfare sentences is: \"+str(desired_percentage*100)+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0dea8a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize features \n",
    "MAX_LEN = 151\n",
    "test_tokenized_feature = tokenizer.batch_encode_plus(\n",
    "                            # Sentences to encode\n",
    "                            test_sentences_cleaned, \n",
    "                            # Add '[CLS]' and '[SEP]'\n",
    "                            add_special_tokens = True,\n",
    "                            # Add empty tokens if len(text)<MAX_LEN\n",
    "                            padding = 'max_length',\n",
    "                            # Truncate all sentences to max length\n",
    "                            truncation=True,\n",
    "                            # Set the maximum length\n",
    "                            max_length = MAX_LEN, \n",
    "                            # Return attention mask\n",
    "                            return_attention_mask = True,\n",
    "                            # Return pytorch tensors\n",
    "                            return_tensors = 'pt'     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09c8d26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataLoader for our test set\n",
    "validation_data = TensorDataset(test_tokenized_feature['input_ids'], test_tokenized_feature['attention_mask'], torch.tensor(test_labels_numbers))\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "245af2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time used is: 463.23 s\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "import numpy as np\n",
    "t0 = time.time()\n",
    "# model in validation mode\n",
    "model.eval()\n",
    "# save prediction\n",
    "predictions,true_labels =[],[]\n",
    "# evaluate data for one epoch\n",
    "for batch in validation_dataloader:\n",
    "    # Add batch to GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Unpack the inputs from our dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    # validation\n",
    "    with torch.no_grad():\n",
    "        outputs = model(b_input_ids,\n",
    "                        token_type_ids=None,\n",
    "                        attention_mask=b_input_mask)\n",
    "    # get output\n",
    "    logits = outputs[0]\n",
    "    # move logits and labels to CPU\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    final_prediction = np.argmax(logits, axis=-1).flatten()\n",
    "    predictions.append(final_prediction)\n",
    "    true_labels.append(label_ids)\n",
    "    \n",
    "print('total time used is: {0:.2f} s'.format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51f50af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear SVC Accuracy on Unseen Test Set: 0.93\n",
      "Linear SVC F1-Score on Unseen Test Set: 0.94\n",
      "Linear SVC Balanced Accuracy on Unseen Test Set: 0.83\n",
      "\n",
      "Linear SVC Classification Report on Unseen Test Set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96     77385\n",
      "           1       0.61      0.71      0.66      7475\n",
      "\n",
      "    accuracy                           0.93     84860\n",
      "   macro avg       0.79      0.83      0.81     84860\n",
      "weighted avg       0.94      0.93      0.94     84860\n",
      "\n",
      "Linear SVC Confusion Matrix on Unseen Test Set:\n",
      "[[73953  3432]\n",
      " [ 2154  5321]]\n"
     ]
    }
   ],
   "source": [
    "# convert numeric label to string\n",
    "final_prediction_list = np.concatenate(predictions)\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(test_labels_numbers, final_prediction_list)\n",
    "\n",
    "# Evaluate F1-score\n",
    "f1_score = f1_score(test_labels_numbers, final_prediction_list, average='weighted')\n",
    "\n",
    "# Evaluate balanced accuracy\n",
    "balanced_accuracy = balanced_accuracy_score(test_labels_numbers, final_prediction_list)\n",
    "\n",
    "\n",
    "# Print evaluation metrics for Linear SVC on the unseen test set\n",
    "print(\"Linear SVC Accuracy on Unseen Test Set:\", round(accuracy,2))\n",
    "print(\"Linear SVC F1-Score on Unseen Test Set:\", round(f1_score,2))\n",
    "print(\"Linear SVC Balanced Accuracy on Unseen Test Set:\", round(balanced_accuracy,2))\n",
    "print()\n",
    "\n",
    "# Print classification report and confusion matrix for Linear SVC on the unseen test set\n",
    "print(\"Linear SVC Classification Report on Unseen Test Set:\")\n",
    "print(classification_report(test_labels_numbers, final_prediction_list))\n",
    "\n",
    "print(\"Linear SVC Confusion Matrix on Unseen Test Set:\")\n",
    "print(confusion_matrix(test_labels_numbers, final_prediction_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31627b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755c6ee6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
